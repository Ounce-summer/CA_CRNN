{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729dae59-368d-43d0-aafc-536ef40af008",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import os\n",
    "import gzip\n",
    "import shutil\n",
    "import logging\n",
    "import random\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import RobertaTokenizer, RobertaModel, AutoTokenizer, AutoModel\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# 启用交互模式，便于实时更新图表\n",
    "plt.ion()\n",
    "\n",
    "# 设置日志记录，同时输出到文件\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "ch = logging.StreamHandler()\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)\n",
    "fh = logging.FileHandler(\"training.log\")\n",
    "fh.setFormatter(formatter)\n",
    "logger.addHandler(fh)\n",
    "\n",
    "# 设置随机种子\n",
    "seed = 30\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# 设置计算设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 检测可用GPU数量\n",
    "num_gpus = torch.cuda.device_count()\n",
    "if num_gpus > 1:\n",
    "    logger.info(f\"Found {num_gpus} GPUs! Using distributed training.\")\n",
    "    use_multi_gpu = True\n",
    "else:\n",
    "    logger.info(f\"Found {num_gpus} GPU. Using single GPU training.\")\n",
    "    use_multi_gpu = False\n",
    "\n",
    "# -------------------------------\n",
    "# 多GPU设置\n",
    "# -------------------------------\n",
    "def setup_ddp(rank, world_size):\n",
    "    \"\"\"\n",
    "    设置分布式数据并行训练\n",
    "    \"\"\"\n",
    "    if use_multi_gpu:\n",
    "        os.environ['MASTER_ADDR'] = 'localhost'\n",
    "        os.environ['MASTER_PORT'] = '12355'\n",
    "        torch.distributed.init_process_group(backend='nccl', init_method='env://', \n",
    "                                            world_size=world_size, rank=rank)\n",
    "        torch.cuda.set_device(rank)\n",
    "\n",
    "def cleanup_ddp():\n",
    "    \"\"\"\n",
    "    清理分布式训练环境\n",
    "    \"\"\"\n",
    "    if use_multi_gpu and torch.distributed.is_initialized():\n",
    "        torch.distributed.destroy_process_group()\n",
    "\n",
    "# -------------------------------\n",
    "# 加载 word2vec 模型和分词器（异常处理）\n",
    "# -------------------------------\n",
    "# logger.info(\"Loading CodeBERT model and tokenizer...\")\n",
    "# try:\n",
    "#     codebert_tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "#     codebert_model = AutoModel.from_pretrained(\"microsoft/codebert-base\")\n",
    "#     codebert_model.to(device)\n",
    "#     codebert_model.eval()\n",
    "#     logger.info(\"CodeBERT loaded successfully!\")\n",
    "# except Exception as e:\n",
    "#     logger.error(\"Failed to load word2vec model. Error: \" + str(e))\n",
    "#     raise e\n",
    "\n",
    "# -------------------------------\n",
    "# 超参数设置（针对 RTX 4090 优化后）\n",
    "# -------------------------------\n",
    "EMBEDDING_DIM = 300  # embedding 输出维度\n",
    "W2VFILE = \"./autodl-tmp/w2v.model\"\n",
    "W2VVECFILE = \"./autodl-tmp/vec.npy\"\n",
    "FILTER_SIZES = [3, 4, 5]\n",
    "NUM_FILTERS = 150\n",
    "HIDDEN_DIM = 256\n",
    "MATCH_COUNT = 240\n",
    "DROPOUT_RATE = 0.5\n",
    "LEARNING_RATE = 0.0005\n",
    "EPOCHS = 10\n",
    "K_FOLDS = 10\n",
    "BATCH_SIZE = 2048\n",
    "ACCUMULATION_STEPS = 1\n",
    "MODEL_SAVE_PATH = \"./models/\"\n",
    "TOP_K = 5\n",
    "BATCH_MAX_LENGTH = 150\n",
    "\n",
    "# -------------------------------\n",
    "# 数据路径设置\n",
    "# CSV 格式：第1列忽略，第2列为标签，第3列为产品，第4列为组件，第5列为 bug 描述\n",
    "# -------------------------------\n",
    "data_dir = \"./data/data_by_ocean/Eclipse_raw/Segmented_content/Complete_data\"\n",
    "os.makedirs(MODEL_SAVE_PATH, exist_ok=True)\n",
    "# 定义保存嵌入数据的文件名\n",
    "EMBEDDING_FILE = \"./autodl-tmp/bug_embeddings.pt\"\n",
    "\n",
    "# -------------------------------\n",
    "# 下载并解压词向量（备用，本例主要使用 CodeBERT）\n",
    "# -------------------------------\n",
    "# word2vec_path = \"./autodl-fs/GoogleNews-vectors-negative300.bin\"\n",
    "# compressed_file = \"./autodl-fs/GoogleNews-vectors-negative300.bin.gz\"\n",
    "# # if not os.path.exists(word2vec_path):\n",
    "# #     logger.info(\"Downloading Word2Vec embeddings...\")\n",
    "# #     urllib.request.urlretrieve(\"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\", compressed_file)\n",
    "# #     logger.info(\"Download complete. Extracting file...\")\n",
    "# #     with gzip.open(compressed_file, 'rb') as f_in:\n",
    "# #         with open(word2vec_path, 'wb') as f_out:\n",
    "# #             shutil.copyfileobj(f_in, f_out)\n",
    "# #     logger.info(\"File extracted successfully!\")\n",
    "# #     os.remove(compressed_file)\n",
    "# # # logger.info(\"Loading Word2Vec embeddings...\")\n",
    "# word2vec = None  # 本例主要使用 CodeBERT\n",
    "\n",
    "# -------------------------------\n",
    "# 数据加载函数\n",
    "# -------------------------------\n",
    "def load_dataset(data_dir):\n",
    "    label_list, product_list, component_list, bug_list = [], [], [], []\n",
    "    label_encoder = LabelEncoder()\n",
    "    product_encoder = LabelEncoder()\n",
    "    component_encoder = LabelEncoder()\n",
    "    \n",
    "    for i in range(11):\n",
    "        file_path = os.path.join(data_dir, f\"{i}.csv\")\n",
    "        if os.path.exists(file_path):\n",
    "            try:\n",
    "                df = pd.read_csv(file_path)\n",
    "                label_list.extend(df.iloc[:, 1].astype(str).tolist())\n",
    "                product_list.extend(df.iloc[:, 2].astype(str).tolist())\n",
    "                component_list.extend(df.iloc[:, 3].astype(str).tolist())\n",
    "                bug_list.extend(df.iloc[:, 4].astype(str).tolist())\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error reading {file_path}: {e}\")\n",
    "                continue\n",
    "        else:\n",
    "            logger.warning(f\"File {file_path} does not exist.\")\n",
    "    \n",
    "    labels_encoded = label_encoder.fit_transform(label_list)\n",
    "    products_encoded = product_encoder.fit_transform(product_list)\n",
    "    components_encoded = component_encoder.fit_transform(component_list)\n",
    "    return labels_encoded, products_encoded, components_encoded, bug_list, label_encoder, product_encoder, component_encoder\n",
    "\n",
    "# -------------------------------\n",
    "# 文本转词嵌入函数\n",
    "# -------------------------------\n",
    "def text_to_embedding(text_list, max_length=BATCH_MAX_LENGTH):\n",
    "    all_word_list = []\n",
    "    # 第一步：构建词列表和文档频率统计\n",
    "    word_doc_count = {}  # 记录每个词出现在多少文档中\n",
    "    total_docs = len(text_list)\n",
    "    logger.info(f\"Computing IDF values for {total_docs} documents...\")\n",
    "    \n",
    "    # 首先遍历所有文档，统计每个词的文档频率\n",
    "    for i in range(0, len(text_list)):\n",
    "        split_text_list = [item.strip().strip(\"'\").strip(\"[\").strip(\"]\") for item in text_list[i].split(\",\")]\n",
    "        # 对文本长度进行调整\n",
    "        if (len(split_text_list) <= max_length):\n",
    "            for i in range(len(split_text_list), max_length):\n",
    "                split_text_list.append(\"pad\")\n",
    "        else:\n",
    "            split_text_list = split_text_list[:max_length]\n",
    "        \n",
    "        # 统计每个词出现的文档数（每个文档中的每个词只计算一次）\n",
    "        unique_words = set(split_text_list)\n",
    "        for word in unique_words:\n",
    "            if word in word_doc_count:\n",
    "                word_doc_count[word] += 1\n",
    "            else:\n",
    "                word_doc_count[word] = 1\n",
    "        \n",
    "        all_word_list.append(split_text_list)\n",
    "    \n",
    "    # 第二步：计算IDF值\n",
    "    word_idf = {}\n",
    "    for word, doc_count in word_doc_count.items():\n",
    "        # 使用log(N/df)计算IDF，加1平滑处理避免零除错误\n",
    "        word_idf[word] = np.log(total_docs / (doc_count + 1)) + 1.0\n",
    "    \n",
    "    # 确保\"pad\"的IDF值为0\n",
    "    word_idf[\"pad\"] = 0.0\n",
    "    \n",
    "    logger.info(f\"IDF calculation complete. Processing {len(all_word_list)} documents with Word2Vec...\")\n",
    "    print(len(all_word_list))\n",
    "    \n",
    "    # 第三步：加载或训练Word2Vec模型\n",
    "    if os.path.exists(W2VFILE):\n",
    "        w2v = Word2Vec.load(W2VFILE)\n",
    "    else:\n",
    "        w2v = Word2Vec(all_word_list,        #用于训练的语料数据\n",
    "                    vector_size=300,    #是指特征向量的维度，默认为100\n",
    "                    window=5,           #一个句子中当前单词和被预测单词的最大距离\n",
    "                    min_count=1)        #可以对字典做截断，词频少于min_count次数的单词会被丢弃掉，默认值为5\n",
    "        print(w2v.wv[\"javadoc\"])\n",
    "        w2v.wv[\"pad\"] = np.zeros(300,dtype=np.float64)\n",
    "        print(w2v.wv[\"pad\"])\n",
    "        print(len(w2v.wv[\"pad\"]))\n",
    "        w2v.save(W2VFILE)\n",
    "    \n",
    "    # 第四步：获取词嵌入并应用IDF加权\n",
    "    flatA = np.array(all_word_list).reshape(-1)\n",
    "    \n",
    "    # 创建IDF加权的词嵌入\n",
    "    idf_weighted_vectors = []\n",
    "    for word in flatA:\n",
    "        # 获取词嵌入\n",
    "        word_vector = w2v.wv[word]\n",
    "        # 获取IDF值并应用加权\n",
    "        idf_value = word_idf.get(word, 1.0)  # 如果未知词，使用默认IDF=1\n",
    "        # 应用IDF加权\n",
    "        weighted_vector = word_vector * idf_value\n",
    "        idf_weighted_vectors.append(weighted_vector)\n",
    "    \n",
    "    vectors = np.array(idf_weighted_vectors)\n",
    "    logger.info(f\"IDF-weighted word embeddings created with shape {vectors.shape}\")\n",
    "    print(vectors.shape)\n",
    "\n",
    "    result_word_tensor = torch.from_numpy(vectors).reshape(-1, max_length, 300)\n",
    "    print(result_word_tensor.shape)\n",
    "    return result_word_tensor\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# 定义增强型 Atten-CRNN 模型（包含产品和组件嵌入、残差链接与 SE 模块）\n",
    "# -------------------------------\n",
    "class AttenCRNNEnhanced(nn.Module):\n",
    "    def __init__(self, num_classes, num_products, num_components):\n",
    "        super(AttenCRNNEnhanced, self).__init__()\n",
    "        self.convs3 = nn.Conv2d(1, NUM_FILTERS, (3, EMBEDDING_DIM))\n",
    "        self.convs4 = nn.Conv2d(1, NUM_FILTERS, (4, EMBEDDING_DIM))\n",
    "        self.convs5 = nn.Conv2d(1, NUM_FILTERS, (5, EMBEDDING_DIM))\n",
    "        self.lstm = nn.LSTM(EMBEDDING_DIM, HIDDEN_DIM, batch_first=True, bidirectional=True)\n",
    "        self.se_reduction = 16\n",
    "        self.se_fc1 = nn.Linear(NUM_FILTERS * len(FILTER_SIZES), (NUM_FILTERS * len(FILTER_SIZES)) // self.se_reduction)\n",
    "        self.se_fc2 = nn.Linear((NUM_FILTERS * len(FILTER_SIZES)) // self.se_reduction, NUM_FILTERS * len(FILTER_SIZES))\n",
    "        \n",
    "        self.product_embed = nn.Embedding(num_products, 32)\n",
    "        self.component_embed = nn.Embedding(num_components, 32)\n",
    "        \n",
    "        self.total_feature_dim = NUM_FILTERS * len(FILTER_SIZES) + HIDDEN_DIM * 2 + 64\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.total_feature_dim, MATCH_COUNT)\n",
    "        self.residual = nn.Linear(self.total_feature_dim, MATCH_COUNT)\n",
    "        self.fc2 = nn.Linear(MATCH_COUNT, num_classes)\n",
    "        self.dropout = nn.Dropout(DROPOUT_RATE)\n",
    "        \n",
    "    def forward(self, text_x, prod_idx, comp_idx):\n",
    "        x = text_x.unsqueeze(1)  # (batch, 1, max_length, EMBEDDING_DIM)\n",
    "        conv3features = F.relu(self.convs3(F.pad(x,(0,0,2,0)))).squeeze(3)    # (batch, NUM_FILTERS, max_length)\n",
    "        conv4features = F.relu(self.convs4(F.pad(x,(0,0,3,0)))).squeeze(3)\n",
    "        conv5features = F.relu(self.convs5(F.pad(x,(0,0,4,0)))).squeeze(3)\n",
    "        cnn_features = torch.cat([conv3features, conv4features, conv5features], 1)  # (batch, NUM_FILTERS * len(FILTER_SIZES), max_length) batchsize 450 150\n",
    "        cnn_features_atten = [F.max_pool1d(cnn_features, cnn_features.size(2)).squeeze(2)] # (batch, NUM_FILTERS * len(FILTER_SIZES))\n",
    "        cnn_features_atten = torch.cat(cnn_features_atten, 1)\n",
    "        se = F.relu(self.se_fc1(cnn_features_atten))  \n",
    "        se = torch.sigmoid(self.se_fc2(se))\n",
    "        se = se.unsqueeze(2).expand(-1, -1, cnn_features.size(2))  # (batch, NUM_FILTERS * len(FILTER_SIZES), max_length)\n",
    "        cnn_features = cnn_features * se    # (batch, NUM_FILTERS * len(FILTER_SIZES))  batchsize 450\n",
    "        \n",
    "        lstm_out, _ = self.lstm(text_x) # (batch, max_length, HIDDEN_DIM * 2) batchsize 150 512\n",
    "        # print(f\"lstm_out.shape={lstm_out.shape}\")\n",
    "        # rnn_features, _ = torch.max(lstm_out, dim=1)   # (batch, HIDDEN_DIM * 2) batchsize 512\n",
    "        # print(f\"rnn_features.shape={rnn_features.shape}\")\n",
    "        \n",
    "        cross_attention = torch.bmm(cnn_features,lstm_out)  #batchsize 450 512\n",
    "        cross_attention = torch.softmax(cross_attention, dim=2)  # (batch, NUM_FILTERS * len(FILTER_SIZES), max_length)\n",
    "\n",
    "        cross_attention_cnn = torch.bmm(cross_attention.permute(0,2,1), cnn_features)  # (batch, NUM_FILTERS * len(FILTER_SIZES), max_length) batchsize 512 150\n",
    "        cross_attention_lstm = torch.bmm(cross_attention, lstm_out.permute(0, 2, 1))  # (batch, NUM_FILTERS * len(FILTER_SIZES), HIDDEN_DIM * 2) batchsize 450 150\n",
    "\n",
    "\n",
    "        # text_features = torch.cat((cnn_features, rnn_features), 1)\n",
    "        cross_attention = torch.cat((cross_attention_cnn, cross_attention_lstm), 1)\n",
    "        cross_attention  = F.max_pool1d(cross_attention, cross_attention.size(2)).squeeze(2)\n",
    "\n",
    "        cross_attention = self.dropout(cross_attention)\n",
    "        \n",
    "        prod_emb = self.product_embed(prod_idx)\n",
    "        comp_emb = self.component_embed(comp_idx)\n",
    "        \n",
    "        combined_features = torch.cat((cross_attention, prod_emb, comp_emb), 1)\n",
    "        \n",
    "        hidden = F.relu(self.fc1(combined_features) + self.residual(combined_features))\n",
    "        output = self.fc2(hidden)\n",
    "        return F.log_softmax(output, dim=1)\n",
    "\n",
    "# -------------------------------\n",
    "# 十折增量学习训练函数（引入 L2 正则化、梯度裁剪；记录当前学习率；优化评价方式与图表输出）\n",
    "# -------------------------------\n",
    "def ten_fold_incremental_learning(model, text_data, prod_data, comp_data, labels, label_encoder):\n",
    "    evaluation_accuracies = []      \n",
    "    evaluation_correct = []         \n",
    "    evaluation_total = []           \n",
    "    evaluation_true_probs = []      \n",
    "    round_final_losses = []         \n",
    "\n",
    "    loss_accuracy_fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "    \n",
    "    # 如果使用多GPU，转换为DDP模型\n",
    "    if use_multi_gpu:\n",
    "        logger.info(\"Preparing model for multi-GPU training...\")\n",
    "        # 使用DataParallel包装模型 - 简单方式\n",
    "        model = nn.DataParallel(model)\n",
    "        logger.info(f\"Model wrapped with DataParallel across {num_gpus} GPUs\")\n",
    "\n",
    "    for i in range(1, 11):\n",
    "        # if i>=5: exit()\n",
    "        try:\n",
    "            test_text = text_data[i]\n",
    "            test_labels = labels[i]\n",
    "            test_prod = prod_data[i]\n",
    "            test_comp = comp_data[i]\n",
    "        except IndexError as e:\n",
    "            logger.error(f\"Data partition index error: {e}\")\n",
    "            break\n",
    "        \n",
    "        print(\"Initializing dataloader\")\n",
    "        train_dataset = TensorDataset(torch.cat(text_data[:i]), torch.cat(prod_data[:i]), torch.cat(comp_data[:i]), torch.cat(labels[:i]))\n",
    "        test_dataset = TensorDataset(test_text, test_prod, test_comp, test_labels)\n",
    "        \n",
    "        # 调整批大小以适应多GPU训练\n",
    "        effective_batch_size = BATCH_SIZE\n",
    "        if use_multi_gpu:\n",
    "            # 确保每个GPU获得相同大小的批次\n",
    "            effective_batch_size = BATCH_SIZE * num_gpus\n",
    "            logger.info(f\"Using effective batch size: {effective_batch_size} ({BATCH_SIZE} per GPU)\")\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=effective_batch_size, shuffle=True, \n",
    "                                 pin_memory=True, num_workers=4 if use_multi_gpu else 2)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=effective_batch_size, shuffle=False, \n",
    "                                pin_memory=True, num_workers=4 if use_multi_gpu else 2)\n",
    "        print(\"Dataloader initialized\")\n",
    "        \n",
    "        optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.9)\n",
    "        \n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        batch_count = 0\n",
    "        epoch_losses = []\n",
    "        \n",
    "        for epoch in range(EPOCHS):\n",
    "            epoch_loss = 0.0\n",
    "            num_batches = 0\n",
    "            for batch in tqdm(train_loader, desc=f\"Round {i} Epoch {epoch+1}/{EPOCHS}\", leave=False):\n",
    "                num_batches += 1\n",
    "                batch_count += 1\n",
    "                batch_text, batch_prod, batch_comp, batch_Y = [b.to(device) for b in batch]\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    outputs = model(batch_text, batch_prod, batch_comp)\n",
    "                    loss = F.cross_entropy(outputs, batch_Y) / ACCUMULATION_STEPS\n",
    "                loss.backward()\n",
    "                # 梯度裁剪\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "                epoch_loss += loss.item() * ACCUMULATION_STEPS\n",
    "                if batch_count % ACCUMULATION_STEPS == 0:\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "                    batch_count = 0\n",
    "            if batch_count != 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                batch_count = 0\n",
    "            scheduler.step()\n",
    "            current_lr = scheduler.get_last_lr()[0]\n",
    "            avg_epoch_loss = epoch_loss / num_batches\n",
    "            epoch_losses.append(avg_epoch_loss)\n",
    "            logger.info(f\"Round {i}, Epoch {epoch+1}/{EPOCHS}: Avg Loss = {avg_epoch_loss:.4f}, LR = {current_lr:.6f}\")\n",
    "        \n",
    "        round_final_losses.append(epoch_losses[-1])\n",
    "        \n",
    "        ax1.cla()\n",
    "        ax1.plot(range(1, len(epoch_losses)+1), epoch_losses, marker='o', color='blue', label='Training Loss')\n",
    "        ax1.set_xlabel(\"Epoch\")\n",
    "        ax1.set_ylabel(\"Training Loss\", color='blue')\n",
    "        ax1.tick_params(axis='y', labelcolor='blue')\n",
    "        \n",
    "        model.eval()\n",
    "        correct_count = 0\n",
    "        total_count = 0\n",
    "        true_prob_sum = 0.0\n",
    "        y_pred_names = []\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                batch_text, batch_prod, batch_comp, batch_Y = [b.to(device) for b in batch]\n",
    "                outputs = model(batch_text, batch_prod, batch_comp)\n",
    "                probs = torch.exp(outputs)\n",
    "                topk_probs, topk_indices = torch.topk(probs, TOP_K, dim=1)\n",
    "                batch_Y_np = batch_Y.cpu().numpy()\n",
    "                for j in range(topk_indices.size(0)):\n",
    "                    candidates = topk_indices[j].cpu().numpy()\n",
    "                    candidate_probs = topk_probs[j].cpu().numpy()\n",
    "                    total_count += 1\n",
    "                    if batch_Y_np[j] in candidates:\n",
    "                        correct_count += 1\n",
    "                        idx = np.where(candidates == batch_Y_np[j])[0][0]\n",
    "                        true_prob_sum += candidate_probs[idx]\n",
    "                    else:\n",
    "                        true_prob_sum += 0.0\n",
    "                    y_pred_names.append(label_encoder.inverse_transform([candidates[0]])[0])\n",
    "        round_accuracy = correct_count / total_count if total_count > 0 else 0\n",
    "        avg_true_prob = true_prob_sum / total_count if total_count > 0 else 0\n",
    "        \n",
    "        evaluation_accuracies.append(round_accuracy)\n",
    "        evaluation_correct.append(correct_count)\n",
    "        evaluation_total.append(total_count)\n",
    "        evaluation_true_probs.append(avg_true_prob)\n",
    "        \n",
    "        logger.info(f\"Round {i} - TOP_K Evaluation: Correct Predictions: {correct_count}, Total Predictions: {total_count}, TOP_K Accuracy: {round_accuracy:.4f}\")\n",
    "        logger.info(f\"Round {i} - Sample predicted bug fixers (top candidate, top 10): {y_pred_names[:TOP_K]}\")\n",
    "        \n",
    "        # 保存模型时，处理多GPU模型的保存\n",
    "        if use_multi_gpu:\n",
    "            model_to_save = model.module  # 获取DataParallel中包装的原始模型\n",
    "        else:\n",
    "            model_to_save = model\n",
    "            \n",
    "        checkpoint = {\n",
    "            'epoch': EPOCHS,\n",
    "            'model_state_dict': model_to_save.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'loss': epoch_losses[-1]\n",
    "        }\n",
    "        if round_accuracy > max(evaluation_accuracies[:-1], default=0):\n",
    "            checkpoint_path = os.path.join(MODEL_SAVE_PATH, f\"model_round_{i}_best.pth\")\n",
    "            torch.save(checkpoint, checkpoint_path)\n",
    "            logger.info(f\"New best model saved at {checkpoint_path}\")\n",
    "        latest_path = os.path.join(MODEL_SAVE_PATH, f\"model_round_{i}_latest.pth\")\n",
    "        torch.save(checkpoint, latest_path)\n",
    "        logger.info(f\"Latest model for Round {i} saved at {latest_path}\")\n",
    "    \n",
    "    final_accuracy = np.mean(evaluation_accuracies) if evaluation_accuracies else 0\n",
    "    logger.info(\"Final Evaluation (Avg over 10 rounds): Accuracy: {:.4f}\".format(final_accuracy))\n",
    "    \n",
    "    rounds = range(1, len(evaluation_accuracies) + 1)\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "    color_loss = 'tab:blue'\n",
    "    ax1.set_xlabel('Round')\n",
    "    ax1.set_ylabel('Final Training Loss', color=color_loss)\n",
    "    ax1.plot(rounds, round_final_losses, marker='o', color=color_loss, label='Training Loss')\n",
    "    ax1.tick_params(axis='y', labelcolor=color_loss)\n",
    "    \n",
    "    ax2 = ax1.twinx()\n",
    "    color_acc = 'tab:red'\n",
    "    ax2.set_ylabel('TOP_K Accuracy', color=color_acc)\n",
    "    ax2.plot(rounds, evaluation_accuracies, marker='s', color=color_acc, label='TOP_K Accuracy')\n",
    "    ax2.tick_params(axis='y', labelcolor=color_acc)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.title(\"Final Training Loss and TOP_K Accuracy per Round\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    plt.ioff()\n",
    "    \n",
    "    # 清理多GPU环境\n",
    "    if use_multi_gpu:\n",
    "        cleanup_ddp()\n",
    "\n",
    "# -------------------------------\n",
    "# 主流程：加载数据、转换，并输出一次数据集详细参数信息\n",
    "# CSV 文件假设包含5列：第1列忽略，第2列为标签，第3列为产品，第4列为组件，第5列为 bug 描述\n",
    "# -------------------------------\n",
    "labels_encoded, products_encoded, components_encoded, bug_list, label_encoder, product_encoder, component_encoder = load_dataset(data_dir)\n",
    "\n",
    "# 检查本地是否存在预先保存的 bug 描述嵌入数据\n",
    "if os.path.exists(EMBEDDING_FILE):\n",
    "    logger.info(\"Loading precomputed bug embeddings from local file...\")\n",
    "    bug_tensor_full = torch.load(EMBEDDING_FILE)\n",
    "else:\n",
    "    logger.info(\"Computing bug embeddings using word2vec...\")\n",
    "    bug_tensor_full = text_to_embedding(bug_list)\n",
    "    torch.save(bug_tensor_full, EMBEDDING_FILE)\n",
    "    logger.info(\"Bug embeddings saved to local file.\") \n",
    "\n",
    "prod_tensor_full = torch.tensor(products_encoded, dtype=torch.long)\n",
    "comp_tensor_full = torch.tensor(components_encoded, dtype=torch.long)\n",
    "label_tensor_full = torch.tensor(labels_encoded, dtype=torch.long)\n",
    "\n",
    "logger.info(\"Bug Text Tensor Shape: \" + str(bug_tensor_full.shape))\n",
    "logger.info(\"Product Tensor Shape: \" + str(prod_tensor_full.shape))\n",
    "logger.info(\"Component Tensor Shape: \" + str(comp_tensor_full.shape))\n",
    "logger.info(\"Label Tensor Shape: \" + str(label_tensor_full.shape))\n",
    "\n",
    "num_parts = 11\n",
    "bug_splits = torch.chunk(bug_tensor_full, num_parts)\n",
    "prod_splits = torch.chunk(prod_tensor_full, num_parts)\n",
    "comp_splits = torch.chunk(comp_tensor_full, num_parts)\n",
    "label_splits = torch.chunk(label_tensor_full, num_parts)\n",
    "\n",
    "# 添加显存优化选项\n",
    "torch.backends.cudnn.benchmark = True  # 启用cudnn自动调优\n",
    "torch.backends.cudnn.deterministic = False  # 允许非确定性优化\n",
    "\n",
    "model = AttenCRNNEnhanced(num_classes=len(label_encoder.classes_),\n",
    "                          num_products=len(product_encoder.classes_),\n",
    "                          num_components=len(component_encoder.classes_)).to(device)\n",
    "\n",
    "# 添加多GPU分布式训练的入口点函数\n",
    "def main_worker():\n",
    "    \"\"\"主进程工作函数，用于启动分布式训练\"\"\"\n",
    "    ten_fold_incremental_learning(model, bug_splits, prod_splits, comp_splits, label_splits, label_encoder)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 单机多卡训练入口\n",
    "    if use_multi_gpu:\n",
    "        # 使用DataParallel模式直接调用\n",
    "        main_worker()\n",
    "    else:\n",
    "        # 单GPU模式\n",
    "        ten_fold_incremental_learning(model, bug_splits, prod_splits, comp_splits, label_splits, label_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f57f213-b2a0-4909-a0e8-1bfe25a45dbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541c8714-3322-42a9-9f1f-78c9d4d71a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 19:47:06,450 - INFO - Found 1 GPU. Using single GPU training.\n",
      "2025-04-17 19:47:10,748 - INFO - Loading precomputed bug embeddings from local file...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import os\n",
    "import gzip\n",
    "import shutil\n",
    "import logging\n",
    "import random\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import RobertaTokenizer, RobertaModel, AutoTokenizer, AutoModel\n",
    "from gensim.models import Word2Vec\n",
    "from thop import profile  \n",
    "\n",
    "# 启用交互模式，便于实时更新图表\n",
    "plt.ion()\n",
    "\n",
    "# 设置日志记录，同时输出到文件\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "ch = logging.StreamHandler()\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)\n",
    "fh = logging.FileHandler(\"training.log\")\n",
    "fh.setFormatter(formatter)\n",
    "logger.addHandler(fh)\n",
    "\n",
    "# 设置随机种子\n",
    "seed = 30\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# 设置计算设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 检测可用GPU数量\n",
    "num_gpus = torch.cuda.device_count()\n",
    "if num_gpus > 1:\n",
    "    logger.info(f\"Found {num_gpus} GPUs! Using distributed training.\")\n",
    "    use_multi_gpu = True\n",
    "else:\n",
    "    logger.info(f\"Found {num_gpus} GPU. Using single GPU training.\")\n",
    "    use_multi_gpu = False\n",
    "\n",
    "# -------------------------------\n",
    "# 多GPU设置\n",
    "# -------------------------------\n",
    "def setup_ddp(rank, world_size):\n",
    "    \"\"\"\n",
    "    设置分布式数据并行训练\n",
    "    \"\"\"\n",
    "    if use_multi_gpu:\n",
    "        os.environ['MASTER_ADDR'] = 'localhost'\n",
    "        os.environ['MASTER_PORT'] = '12355'\n",
    "        torch.distributed.init_process_group(backend='nccl', init_method='env://', \n",
    "                                            world_size=world_size, rank=rank)\n",
    "        torch.cuda.set_device(rank)\n",
    "\n",
    "def cleanup_ddp():\n",
    "    \"\"\"\n",
    "    清理分布式训练环境\n",
    "    \"\"\"\n",
    "    if use_multi_gpu and torch.distributed.is_initialized():\n",
    "        torch.distributed.destroy_process_group()\n",
    "\n",
    "# -------------------------------\n",
    "# 加载 word2vec 模型和分词器（异常处理）\n",
    "# -------------------------------\n",
    "# logger.info(\"Loading CodeBERT model and tokenizer...\")\n",
    "# try:\n",
    "#     codebert_tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "#     codebert_model = AutoModel.from_pretrained(\"microsoft/codebert-base\")\n",
    "#     codebert_model.to(device)\n",
    "#     codebert_model.eval()\n",
    "#     logger.info(\"CodeBERT loaded successfully!\")\n",
    "# except Exception as e:\n",
    "#     logger.error(\"Failed to load word2vec model. Error: \" + str(e))\n",
    "#     raise e\n",
    "\n",
    "# -------------------------------\n",
    "# 超参数设置（针对 RTX 4090 优化后）\n",
    "# -------------------------------\n",
    "EMBEDDING_DIM = 300  # embedding 输出维度\n",
    "W2VFILE = \"./autodl-tmp/w2v.model\"\n",
    "W2VVECFILE = \"./autodl-tmp/vec.npy\"\n",
    "FILTER_SIZES = [3, 4, 5]\n",
    "NUM_FILTERS = 150\n",
    "HIDDEN_DIM = 256\n",
    "MATCH_COUNT = 240\n",
    "DROPOUT_RATE = 0.5\n",
    "LEARNING_RATE = 0.0005\n",
    "EPOCHS = 10\n",
    "K_FOLDS = 10\n",
    "BATCH_SIZE = 2048\n",
    "ACCUMULATION_STEPS = 1\n",
    "MODEL_SAVE_PATH = \"./models/\"\n",
    "TOP_K = 5\n",
    "BATCH_MAX_LENGTH = 150\n",
    "\n",
    "# -------------------------------\n",
    "# 数据路径设置\n",
    "# CSV 格式：第1列忽略，第2列为标签，第3列为产品，第4列为组件，第5列为 bug 描述\n",
    "# -------------------------------\n",
    "data_dir = \"./data/data_by_ocean/Eclipse_raw/Segmented_content/Complete_data\"\n",
    "os.makedirs(MODEL_SAVE_PATH, exist_ok=True)\n",
    "# 定义保存嵌入数据的文件名\n",
    "EMBEDDING_FILE = \"./autodl-tmp/bug_embeddings.pt\"\n",
    "\n",
    "# -------------------------------\n",
    "# 下载并解压词向量（备用，本例主要使用 CodeBERT）\n",
    "# -------------------------------\n",
    "# word2vec_path = \"./autodl-fs/GoogleNews-vectors-negative300.bin\"\n",
    "# compressed_file = \"./autodl-fs/GoogleNews-vectors-negative300.bin.gz\"\n",
    "# # if not os.path.exists(word2vec_path):\n",
    "# #     logger.info(\"Downloading Word2Vec embeddings...\")\n",
    "# #     urllib.request.urlretrieve(\"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\", compressed_file)\n",
    "# #     logger.info(\"Download complete. Extracting file...\")\n",
    "# #     with gzip.open(compressed_file, 'rb') as f_in:\n",
    "# #         with open(word2vec_path, 'wb') as f_out:\n",
    "# #             shutil.copyfileobj(f_in, f_out)\n",
    "# #     logger.info(\"File extracted successfully!\")\n",
    "# #     os.remove(compressed_file)\n",
    "# # # logger.info(\"Loading Word2Vec embeddings...\")\n",
    "# word2vec = None  # 本例主要使用 CodeBERT\n",
    "\n",
    "# -------------------------------\n",
    "# 数据加载函数\n",
    "# -------------------------------\n",
    "def load_dataset(data_dir):\n",
    "    label_list, product_list, component_list, bug_list = [], [], [], []\n",
    "    label_encoder = LabelEncoder()\n",
    "    product_encoder = LabelEncoder()\n",
    "    component_encoder = LabelEncoder()\n",
    "    \n",
    "    for i in range(11):\n",
    "        file_path = os.path.join(data_dir, f\"{i}.csv\")\n",
    "        if os.path.exists(file_path):\n",
    "            try:\n",
    "                df = pd.read_csv(file_path)\n",
    "                label_list.extend(df.iloc[:, 1].astype(str).tolist())\n",
    "                product_list.extend(df.iloc[:, 2].astype(str).tolist())\n",
    "                component_list.extend(df.iloc[:, 3].astype(str).tolist())\n",
    "                bug_list.extend(df.iloc[:, 4].astype(str).tolist())\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error reading {file_path}: {e}\")\n",
    "                continue\n",
    "        else:\n",
    "            logger.warning(f\"File {file_path} does not exist.\")\n",
    "    \n",
    "    labels_encoded = label_encoder.fit_transform(label_list)\n",
    "    products_encoded = product_encoder.fit_transform(product_list)\n",
    "    components_encoded = component_encoder.fit_transform(component_list)\n",
    "    return labels_encoded, products_encoded, components_encoded, bug_list, label_encoder, product_encoder, component_encoder\n",
    "\n",
    "# -------------------------------\n",
    "# 文本转词嵌入函数\n",
    "# -------------------------------\n",
    "def text_to_embedding(text_list, max_length=BATCH_MAX_LENGTH):\n",
    "    all_word_list = []\n",
    "    # 第一步：构建词列表和文档频率统计\n",
    "    word_doc_count = {}  # 记录每个词出现在多少文档中\n",
    "    total_docs = len(text_list)\n",
    "    logger.info(f\"Computing IDF values for {total_docs} documents...\")\n",
    "    \n",
    "    # 首先遍历所有文档，统计每个词的文档频率\n",
    "    for i in range(0, len(text_list)):\n",
    "        split_text_list = [item.strip().strip(\"'\").strip(\"[\").strip(\"]\") for item in text_list[i].split(\",\")]\n",
    "        # 对文本长度进行调整\n",
    "        if (len(split_text_list) <= max_length):\n",
    "            for i in range(len(split_text_list), max_length):\n",
    "                split_text_list.append(\"pad\")\n",
    "        else:\n",
    "            split_text_list = split_text_list[:max_length]\n",
    "        \n",
    "        # 统计每个词出现的文档数（每个文档中的每个词只计算一次）\n",
    "        unique_words = set(split_text_list)\n",
    "        for word in unique_words:\n",
    "            if word in word_doc_count:\n",
    "                word_doc_count[word] += 1\n",
    "            else:\n",
    "                word_doc_count[word] = 1\n",
    "        \n",
    "        all_word_list.append(split_text_list)\n",
    "    \n",
    "    # 第二步：计算IDF值\n",
    "    word_idf = {}\n",
    "    for word, doc_count in word_doc_count.items():\n",
    "        # 使用log(N/df)计算IDF，加1平滑处理避免零除错误\n",
    "        word_idf[word] = np.log(total_docs / (doc_count + 1)) + 1.0\n",
    "    \n",
    "    # 确保\"pad\"的IDF值为0\n",
    "    word_idf[\"pad\"] = 0.0\n",
    "    \n",
    "    logger.info(f\"IDF calculation complete. Processing {len(all_word_list)} documents with Word2Vec...\")\n",
    "    print(len(all_word_list))\n",
    "    \n",
    "    # 第三步：加载或训练Word2Vec模型\n",
    "    if os.path.exists(W2VFILE):\n",
    "        w2v = Word2Vec.load(W2VFILE)\n",
    "    else:\n",
    "        w2v = Word2Vec(all_word_list,        #用于训练的语料数据\n",
    "                    vector_size=300,    #是指特征向量的维度，默认为100\n",
    "                    window=5,           #一个句子中当前单词和被预测单词的最大距离\n",
    "                    min_count=1)        #可以对字典做截断，词频少于min_count次数的单词会被丢弃掉，默认值为5\n",
    "        print(w2v.wv[\"javadoc\"])\n",
    "        w2v.wv[\"pad\"] = np.zeros(300,dtype=np.float64)\n",
    "        print(w2v.wv[\"pad\"])\n",
    "        print(len(w2v.wv[\"pad\"]))\n",
    "        w2v.save(W2VFILE)\n",
    "    \n",
    "    # 第四步：获取词嵌入并应用IDF加权\n",
    "    flatA = np.array(all_word_list).reshape(-1)\n",
    "    \n",
    "    # 创建IDF加权的词嵌入\n",
    "    idf_weighted_vectors = []\n",
    "    for word in flatA:\n",
    "        # 获取词嵌入\n",
    "        word_vector = w2v.wv[word]\n",
    "        # 获取IDF值并应用加权\n",
    "        idf_value = word_idf.get(word, 1.0)  # 如果未知词，使用默认IDF=1\n",
    "        # 应用IDF加权\n",
    "        weighted_vector = word_vector * idf_value\n",
    "        idf_weighted_vectors.append(weighted_vector)\n",
    "    \n",
    "    vectors = np.array(idf_weighted_vectors)\n",
    "    logger.info(f\"IDF-weighted word embeddings created with shape {vectors.shape}\")\n",
    "    print(vectors.shape)\n",
    "\n",
    "    result_word_tensor = torch.from_numpy(vectors).reshape(-1, max_length, 300)\n",
    "    print(result_word_tensor.shape)\n",
    "    return result_word_tensor\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# 定义增强型 Atten-CRNN 模型（包含产品和组件嵌入、残差链接与 SE 模块）\n",
    "# -------------------------------\n",
    "class AttenCRNNEnhanced(nn.Module):\n",
    "    def __init__(self, num_classes, num_products, num_components):\n",
    "        super(AttenCRNNEnhanced, self).__init__()\n",
    "        self.convs3 = nn.Conv2d(1, NUM_FILTERS, (3, EMBEDDING_DIM))\n",
    "        self.convs4 = nn.Conv2d(1, NUM_FILTERS, (4, EMBEDDING_DIM))\n",
    "        self.convs5 = nn.Conv2d(1, NUM_FILTERS, (5, EMBEDDING_DIM))\n",
    "        self.lstm = nn.LSTM(EMBEDDING_DIM, HIDDEN_DIM, batch_first=True, bidirectional=True)\n",
    "        self.se_reduction = 16\n",
    "        self.se_fc1 = nn.Linear(NUM_FILTERS * len(FILTER_SIZES), (NUM_FILTERS * len(FILTER_SIZES)) // self.se_reduction)\n",
    "        self.se_fc2 = nn.Linear((NUM_FILTERS * len(FILTER_SIZES)) // self.se_reduction, NUM_FILTERS * len(FILTER_SIZES))\n",
    "        \n",
    "        self.product_embed = nn.Embedding(num_products, 32)\n",
    "        self.component_embed = nn.Embedding(num_components, 32)\n",
    "        \n",
    "        self.total_feature_dim = NUM_FILTERS * len(FILTER_SIZES) + HIDDEN_DIM * 2 + 64\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.total_feature_dim, MATCH_COUNT)\n",
    "        self.residual = nn.Linear(self.total_feature_dim, MATCH_COUNT)\n",
    "        self.fc2 = nn.Linear(MATCH_COUNT, num_classes)\n",
    "        self.dropout = nn.Dropout(DROPOUT_RATE)\n",
    "        \n",
    "    def forward(self, text_x, prod_idx, comp_idx):\n",
    "        x = text_x.unsqueeze(1)  # (batch, 1, max_length, EMBEDDING_DIM)\n",
    "        conv3features = F.relu(self.convs3(F.pad(x,(0,0,2,0)))).squeeze(3)    # (batch, NUM_FILTERS, max_length)\n",
    "        conv4features = F.relu(self.convs4(F.pad(x,(0,0,3,0)))).squeeze(3)\n",
    "        conv5features = F.relu(self.convs5(F.pad(x,(0,0,4,0)))).squeeze(3)\n",
    "        cnn_features = torch.cat([conv3features, conv4features, conv5features], 1)  # (batch, NUM_FILTERS * len(FILTER_SIZES), max_length) batchsize 450 150\n",
    "        cnn_features_atten = [F.max_pool1d(cnn_features, cnn_features.size(2)).squeeze(2)] # (batch, NUM_FILTERS * len(FILTER_SIZES))\n",
    "        cnn_features_atten = torch.cat(cnn_features_atten, 1)\n",
    "        se = F.relu(self.se_fc1(cnn_features_atten))  \n",
    "        se = torch.sigmoid(self.se_fc2(se))\n",
    "        se = se.unsqueeze(2).expand(-1, -1, cnn_features.size(2))  # (batch, NUM_FILTERS * len(FILTER_SIZES), max_length)\n",
    "        cnn_features = cnn_features * se    # (batch, NUM_FILTERS * len(FILTER_SIZES))  batchsize 450\n",
    "        \n",
    "        lstm_out, _ = self.lstm(text_x) # (batch, max_length, HIDDEN_DIM * 2) batchsize 150 512\n",
    "        # print(f\"lstm_out.shape={lstm_out.shape}\")\n",
    "        # rnn_features, _ = torch.max(lstm_out, dim=1)   # (batch, HIDDEN_DIM * 2) batchsize 512\n",
    "        # print(f\"rnn_features.shape={rnn_features.shape}\")\n",
    "        \n",
    "        cross_attention = torch.bmm(cnn_features,lstm_out)  #batchsize 450 512\n",
    "        cross_attention = torch.softmax(cross_attention, dim=2)  # (batch, NUM_FILTERS * len(FILTER_SIZES), max_length)\n",
    "\n",
    "        cross_attention_cnn = torch.bmm(cross_attention.permute(0,2,1), cnn_features)  # (batch, NUM_FILTERS * len(FILTER_SIZES), max_length) batchsize 512 150\n",
    "        cross_attention_lstm = torch.bmm(cross_attention, lstm_out.permute(0, 2, 1))  # (batch, NUM_FILTERS * len(FILTER_SIZES), HIDDEN_DIM * 2) batchsize 450 150\n",
    "\n",
    "\n",
    "        # text_features = torch.cat((cnn_features, rnn_features), 1)\n",
    "        cross_attention = torch.cat((cross_attention_cnn, cross_attention_lstm), 1)\n",
    "        cross_attention  = F.max_pool1d(cross_attention, cross_attention.size(2)).squeeze(2)\n",
    "\n",
    "        cross_attention = self.dropout(cross_attention)\n",
    "        \n",
    "        prod_emb = self.product_embed(prod_idx)\n",
    "        comp_emb = self.component_embed(comp_idx)\n",
    "        \n",
    "        combined_features = torch.cat((cross_attention, prod_emb, comp_emb), 1)\n",
    "        \n",
    "        hidden = F.relu(self.fc1(combined_features) + self.residual(combined_features))\n",
    "        output = self.fc2(hidden)\n",
    "        return F.log_softmax(output, dim=1)\n",
    "\n",
    "# -------------------------------\n",
    "# 十折增量学习训练函数（引入 L2 正则化、梯度裁剪；记录当前学习率；优化评价方式与图表输出）\n",
    "# -------------------------------\n",
    "def ten_fold_incremental_learning(model, text_data, prod_data, comp_data, labels, label_encoder):\n",
    "    evaluation_accuracies = []      \n",
    "    evaluation_correct = []         \n",
    "    evaluation_total = []           \n",
    "    evaluation_true_probs = []      \n",
    "    round_final_losses = []         \n",
    "\n",
    "    loss_accuracy_fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "    \n",
    "    # 如果使用多GPU，转换为DDP模型\n",
    "    if use_multi_gpu:\n",
    "        logger.info(\"Preparing model for multi-GPU training...\")\n",
    "        # 使用DataParallel包装模型 - 简单方式\n",
    "        model = nn.DataParallel(model)\n",
    "        logger.info(f\"Model wrapped with DataParallel across {num_gpus} GPUs\")\n",
    "\n",
    "    for i in range(1, 11):\n",
    "        # if i>=5: exit()\n",
    "        try:\n",
    "            test_text = text_data[i]\n",
    "            test_labels = labels[i]\n",
    "            test_prod = prod_data[i]\n",
    "            test_comp = comp_data[i]\n",
    "        except IndexError as e:\n",
    "            logger.error(f\"Data partition index error: {e}\")\n",
    "            break\n",
    "        \n",
    "        print(\"Initializing dataloader\")\n",
    "        train_dataset = TensorDataset(torch.cat(text_data[:i]), torch.cat(prod_data[:i]), torch.cat(comp_data[:i]), torch.cat(labels[:i]))\n",
    "        test_dataset = TensorDataset(test_text, test_prod, test_comp, test_labels)\n",
    "        \n",
    "        # 调整批大小以适应多GPU训练\n",
    "        effective_batch_size = BATCH_SIZE\n",
    "        if use_multi_gpu:\n",
    "            # 确保每个GPU获得相同大小的批次\n",
    "            effective_batch_size = BATCH_SIZE * num_gpus\n",
    "            logger.info(f\"Using effective batch size: {effective_batch_size} ({BATCH_SIZE} per GPU)\")\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=effective_batch_size, shuffle=True, \n",
    "                                 pin_memory=True, num_workers=4 if use_multi_gpu else 2)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=effective_batch_size, shuffle=False, \n",
    "                                pin_memory=True, num_workers=4 if use_multi_gpu else 2)\n",
    "        print(\"Dataloader initialized\")\n",
    "        \n",
    "        optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.9)\n",
    "        \n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        batch_count = 0\n",
    "        epoch_losses = []\n",
    "        \n",
    "        for epoch in range(EPOCHS):\n",
    "            epoch_loss = 0.0\n",
    "            num_batches = 0\n",
    "            for batch in tqdm(train_loader, desc=f\"Round {i} Epoch {epoch+1}/{EPOCHS}\", leave=False):\n",
    "                num_batches += 1\n",
    "                batch_count += 1\n",
    "                batch_text, batch_prod, batch_comp, batch_Y = [b.to(device) for b in batch]\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    outputs = model(batch_text, batch_prod, batch_comp)\n",
    "                    loss = F.cross_entropy(outputs, batch_Y) / ACCUMULATION_STEPS\n",
    "                loss.backward()\n",
    "                # 梯度裁剪\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "                epoch_loss += loss.item() * ACCUMULATION_STEPS\n",
    "                if batch_count % ACCUMULATION_STEPS == 0:\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "                    batch_count = 0\n",
    "            if batch_count != 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                batch_count = 0\n",
    "            scheduler.step()\n",
    "            current_lr = scheduler.get_last_lr()[0]\n",
    "            avg_epoch_loss = epoch_loss / num_batches\n",
    "            epoch_losses.append(avg_epoch_loss)\n",
    "            logger.info(f\"Round {i}, Epoch {epoch+1}/{EPOCHS}: Avg Loss = {avg_epoch_loss:.4f}, LR = {current_lr:.6f}\")\n",
    "        \n",
    "        round_final_losses.append(epoch_losses[-1])\n",
    "        \n",
    "        ax1.cla()\n",
    "        ax1.plot(range(1, len(epoch_losses)+1), epoch_losses, marker='o', color='blue', label='Training Loss')\n",
    "        ax1.set_xlabel(\"Epoch\")\n",
    "        ax1.set_ylabel(\"Training Loss\", color='blue')\n",
    "        ax1.tick_params(axis='y', labelcolor='blue')\n",
    "        \n",
    "        model.eval()\n",
    "        correct_count = 0\n",
    "        total_count = 0\n",
    "        true_prob_sum = 0.0\n",
    "        y_pred_names = []\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                batch_text, batch_prod, batch_comp, batch_Y = [b.to(device) for b in batch]\n",
    "                outputs = model(batch_text, batch_prod, batch_comp)\n",
    "                probs = torch.exp(outputs)\n",
    "                topk_probs, topk_indices = torch.topk(probs, TOP_K, dim=1)\n",
    "                batch_Y_np = batch_Y.cpu().numpy()\n",
    "                for j in range(topk_indices.size(0)):\n",
    "                    candidates = topk_indices[j].cpu().numpy()\n",
    "                    candidate_probs = topk_probs[j].cpu().numpy()\n",
    "                    total_count += 1\n",
    "                    if batch_Y_np[j] in candidates:\n",
    "                        correct_count += 1\n",
    "                        idx = np.where(candidates == batch_Y_np[j])[0][0]\n",
    "                        true_prob_sum += candidate_probs[idx]\n",
    "                    else:\n",
    "                        true_prob_sum += 0.0\n",
    "                    y_pred_names.append(label_encoder.inverse_transform([candidates[0]])[0])\n",
    "        round_accuracy = correct_count / total_count if total_count > 0 else 0\n",
    "        avg_true_prob = true_prob_sum / total_count if total_count > 0 else 0\n",
    "        \n",
    "        evaluation_accuracies.append(round_accuracy)\n",
    "        evaluation_correct.append(correct_count)\n",
    "        evaluation_total.append(total_count)\n",
    "        evaluation_true_probs.append(avg_true_prob)\n",
    "        \n",
    "        logger.info(f\"Round {i} - TOP_K Evaluation: Correct Predictions: {correct_count}, Total Predictions: {total_count}, TOP_K Accuracy: {round_accuracy:.4f}\")\n",
    "        logger.info(f\"Round {i} - Sample predicted bug fixers (top candidate, top 10): {y_pred_names[:TOP_K]}\")\n",
    "        \n",
    "        # 保存模型时，处理多GPU模型的保存\n",
    "        if use_multi_gpu:\n",
    "            model_to_save = model.module  # 获取DataParallel中包装的原始模型\n",
    "        else:\n",
    "            model_to_save = model\n",
    "            \n",
    "        checkpoint = {\n",
    "            'epoch': EPOCHS,\n",
    "            'model_state_dict': model_to_save.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'loss': epoch_losses[-1]\n",
    "        }\n",
    "        if round_accuracy > max(evaluation_accuracies[:-1], default=0):\n",
    "            checkpoint_path = os.path.join(MODEL_SAVE_PATH, f\"model_round_{i}_best.pth\")\n",
    "            torch.save(checkpoint, checkpoint_path)\n",
    "            logger.info(f\"New best model saved at {checkpoint_path}\")\n",
    "        latest_path = os.path.join(MODEL_SAVE_PATH, f\"model_round_{i}_latest.pth\")\n",
    "        torch.save(checkpoint, latest_path)\n",
    "        logger.info(f\"Latest model for Round {i} saved at {latest_path}\")\n",
    "    \n",
    "    final_accuracy = np.mean(evaluation_accuracies) if evaluation_accuracies else 0\n",
    "    logger.info(\"Final Evaluation (Avg over 10 rounds): Accuracy: {:.4f}\".format(final_accuracy))\n",
    "    \n",
    "    rounds = range(1, len(evaluation_accuracies) + 1)\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "    color_loss = 'tab:blue'\n",
    "    ax1.set_xlabel('Round')\n",
    "    ax1.set_ylabel('Final Training Loss', color=color_loss)\n",
    "    ax1.plot(rounds, round_final_losses, marker='o', color=color_loss, label='Training Loss')\n",
    "    ax1.tick_params(axis='y', labelcolor=color_loss)\n",
    "    \n",
    "    ax2 = ax1.twinx()\n",
    "    color_acc = 'tab:red'\n",
    "    ax2.set_ylabel('TOP_K Accuracy', color=color_acc)\n",
    "    ax2.plot(rounds, evaluation_accuracies, marker='s', color=color_acc, label='TOP_K Accuracy')\n",
    "    ax2.tick_params(axis='y', labelcolor=color_acc)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.title(\"Final Training Loss and TOP_K Accuracy per Round\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    plt.ioff()\n",
    "    \n",
    "    # 清理多GPU环境\n",
    "    if use_multi_gpu:\n",
    "        cleanup_ddp()\n",
    "\n",
    "# -------------------------------\n",
    "# 主流程：加载数据、转换，并输出一次数据集详细参数信息\n",
    "# CSV 文件假设包含5列：第1列忽略，第2列为标签，第3列为产品，第4列为组件，第5列为 bug 描述\n",
    "# -------------------------------\n",
    "labels_encoded, products_encoded, components_encoded, bug_list, label_encoder, product_encoder, component_encoder = load_dataset(data_dir)\n",
    "\n",
    "# 检查本地是否存在预先保存的 bug 描述嵌入数据\n",
    "if os.path.exists(EMBEDDING_FILE):\n",
    "    logger.info(\"Loading precomputed bug embeddings from local file...\")\n",
    "    bug_tensor_full = torch.load(EMBEDDING_FILE)\n",
    "else:\n",
    "    logger.info(\"Computing bug embeddings using word2vec...\")\n",
    "    bug_tensor_full = text_to_embedding(bug_list)\n",
    "    torch.save(bug_tensor_full, EMBEDDING_FILE)\n",
    "    logger.info(\"Bug embeddings saved to local file.\") \n",
    "\n",
    "prod_tensor_full = torch.tensor(products_encoded, dtype=torch.long)\n",
    "comp_tensor_full = torch.tensor(components_encoded, dtype=torch.long)\n",
    "label_tensor_full = torch.tensor(labels_encoded, dtype=torch.long)\n",
    "\n",
    "logger.info(\"Bug Text Tensor Shape: \" + str(bug_tensor_full.shape))\n",
    "logger.info(\"Product Tensor Shape: \" + str(prod_tensor_full.shape))\n",
    "logger.info(\"Component Tensor Shape: \" + str(comp_tensor_full.shape))\n",
    "logger.info(\"Label Tensor Shape: \" + str(label_tensor_full.shape))\n",
    "\n",
    "num_parts = 11\n",
    "bug_splits = torch.chunk(bug_tensor_full, num_parts)\n",
    "prod_splits = torch.chunk(prod_tensor_full, num_parts)\n",
    "comp_splits = torch.chunk(comp_tensor_full, num_parts)\n",
    "label_splits = torch.chunk(label_tensor_full, num_parts)\n",
    "\n",
    "# 添加显存优化选项\n",
    "torch.backends.cudnn.benchmark = True  # 启用cudnn自动调优\n",
    "torch.backends.cudnn.deterministic = False  # 允许非确定性优化\n",
    "\n",
    "model = AttenCRNNEnhanced(num_classes=len(label_encoder.classes_),\n",
    "                          num_products=len(product_encoder.classes_),\n",
    "                          num_components=len(component_encoder.classes_)).to(device)\n",
    "\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# 2. 统计参数量\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"模型可训练参数量: {total_params / 1e6:.2f} M\")\n",
    "\n",
    "# 3. 统计 FLOPs（以单样本输入为例）\n",
    "#    输入维度: (batch_size=1, seq_len=BATCH_MAX_LENGTH, embed_dim=EMBEDDING_DIM)\n",
    "dummy_text = torch.randn(1, BATCH_MAX_LENGTH, EMBEDDING_DIM).to(device)\n",
    "dummy_prod = torch.zeros(1, dtype=torch.long).to(device)\n",
    "dummy_comp = torch.zeros(1, dtype=torch.long).to(device)\n",
    "\n",
    "flops, params = profile(\n",
    "    model, \n",
    "    inputs=(dummy_text, dummy_prod, dummy_comp),\n",
    "    verbose=False\n",
    ")\n",
    "print(f\"FLOPs: {flops / 1e9:.3f} G  |  参数量 (thop 计算): {params / 1e6:.2f} M\")\n",
    "\n",
    "# 添加多GPU分布式训练的入口点函数\n",
    "def main_worker():\n",
    "    \"\"\"主进程工作函数，用于启动分布式训练\"\"\"\n",
    "    ten_fold_incremental_learning(model, bug_splits, prod_splits, comp_splits, label_splits, label_encoder)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 单机多卡训练入口\n",
    "    if use_multi_gpu:\n",
    "        # 使用DataParallel模式直接调用\n",
    "        main_worker()\n",
    "    else:\n",
    "        # 单GPU模式\n",
    "        ten_fold_incremental_learning(model, bug_splits, prod_splits, comp_splits, label_splits, label_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67af8894-0d4d-4847-b480-4d4067c4d849",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
