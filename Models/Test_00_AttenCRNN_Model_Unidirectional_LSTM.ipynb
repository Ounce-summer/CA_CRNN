{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72fd5a29-4200-4974-9be2-30572ebbf97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 19:42:14,182 - INFO - Found 1 GPU. Using single GPU training.\n",
      "2025-04-17 19:42:18,435 - INFO - Loading precomputed bug embeddings from local file...\n",
      "2025-04-17 19:42:43,562 - INFO - Bug Text Tensor Shape: torch.Size([199947, 150, 300])\n",
      "2025-04-17 19:42:43,565 - INFO - Product Tensor Shape: torch.Size([199947])\n",
      "2025-04-17 19:42:43,566 - INFO - Component Tensor Shape: torch.Size([199947])\n",
      "2025-04-17 19:42:43,566 - INFO - Label Tensor Shape: torch.Size([199947])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型可训练参数量: 2.30 M\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'profile' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 527\u001b[0m\n\u001b[1;32m    524\u001b[0m dummy_prod \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    525\u001b[0m dummy_comp \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 527\u001b[0m flops, params \u001b[38;5;241m=\u001b[39m \u001b[43mprofile\u001b[49m(\n\u001b[1;32m    528\u001b[0m     model, \n\u001b[1;32m    529\u001b[0m     inputs\u001b[38;5;241m=\u001b[39m(dummy_text, dummy_prod, dummy_comp),\n\u001b[1;32m    530\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    531\u001b[0m )\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFLOPs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mflops\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1e9\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m G  |  参数量 (thop 计算): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1e6\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m M\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m# 添加多GPU分布式训练的入口点函数\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'profile' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import os\n",
    "import gzip\n",
    "import shutil\n",
    "import logging\n",
    "import random\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import RobertaTokenizer, RobertaModel, AutoTokenizer, AutoModel\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# 启用交互模式，便于实时更新图表\n",
    "plt.ion()\n",
    "\n",
    "# 设置日志记录，同时输出到文件\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "ch = logging.StreamHandler()\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)\n",
    "fh = logging.FileHandler(\"training.log\")\n",
    "fh.setFormatter(formatter)\n",
    "logger.addHandler(fh)\n",
    "\n",
    "# 设置随机种子\n",
    "seed = 30\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# 设置计算设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 检测可用GPU数量\n",
    "num_gpus = torch.cuda.device_count()\n",
    "if num_gpus > 1:\n",
    "    logger.info(f\"Found {num_gpus} GPUs! Using distributed training.\")\n",
    "    use_multi_gpu = True\n",
    "else:\n",
    "    logger.info(f\"Found {num_gpus} GPU. Using single GPU training.\")\n",
    "    use_multi_gpu = False\n",
    "\n",
    "# -------------------------------\n",
    "# 多GPU设置\n",
    "# -------------------------------\n",
    "def setup_ddp(rank, world_size):\n",
    "    \"\"\"\n",
    "    设置分布式数据并行训练\n",
    "    \"\"\"\n",
    "    if use_multi_gpu:\n",
    "        os.environ['MASTER_ADDR'] = 'localhost'\n",
    "        os.environ['MASTER_PORT'] = '12355'\n",
    "        torch.distributed.init_process_group(backend='nccl', init_method='env://', \n",
    "                                            world_size=world_size, rank=rank)\n",
    "        torch.cuda.set_device(rank)\n",
    "\n",
    "def cleanup_ddp():\n",
    "    \"\"\"\n",
    "    清理分布式训练环境\n",
    "    \"\"\"\n",
    "    if use_multi_gpu and torch.distributed.is_initialized():\n",
    "        torch.distributed.destroy_process_group()\n",
    "\n",
    "# -------------------------------\n",
    "# 加载 word2vec 模型和分词器（异常处理）\n",
    "# -------------------------------\n",
    "# logger.info(\"Loading CodeBERT model and tokenizer...\")\n",
    "# try:\n",
    "#     codebert_tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "#     codebert_model = AutoModel.from_pretrained(\"microsoft/codebert-base\")\n",
    "#     codebert_model.to(device)\n",
    "#     codebert_model.eval()\n",
    "#     logger.info(\"CodeBERT loaded successfully!\")\n",
    "# except Exception as e:\n",
    "#     logger.error(\"Failed to load word2vec model. Error: \" + str(e))\n",
    "#     raise e\n",
    "\n",
    "# -------------------------------\n",
    "# 超参数设置（针对 RTX 4090 优化后）\n",
    "# -------------------------------\n",
    "EMBEDDING_DIM = 300  # embedding 输出维度\n",
    "W2VFILE = \"./autodl-tmp/w2v.model\"\n",
    "W2VVECFILE = \"./autodl-tmp/vec.npy\"\n",
    "FILTER_SIZES = [3, 4, 5]\n",
    "NUM_FILTERS = 150\n",
    "HIDDEN_DIM = 256\n",
    "MATCH_COUNT = 240\n",
    "DROPOUT_RATE = 0.5\n",
    "LEARNING_RATE = 0.0005\n",
    "EPOCHS = 10\n",
    "K_FOLDS = 10\n",
    "BATCH_SIZE = 2048\n",
    "ACCUMULATION_STEPS = 1\n",
    "MODEL_SAVE_PATH = \"./models/\"\n",
    "TOP_K = 5\n",
    "BATCH_MAX_LENGTH = 150\n",
    "\n",
    "# -------------------------------\n",
    "# 数据路径设置\n",
    "# CSV 格式：第1列忽略，第2列为标签，第3列为产品，第4列为组件，第5列为 bug 描述\n",
    "# -------------------------------\n",
    "data_dir = \"./data/data_by_ocean/Eclipse_raw/Segmented_content/Complete_data\"\n",
    "os.makedirs(MODEL_SAVE_PATH, exist_ok=True)\n",
    "# 定义保存嵌入数据的文件名\n",
    "EMBEDDING_FILE = \"./autodl-tmp/bug_embeddings.pt\"\n",
    "\n",
    "# -------------------------------\n",
    "# 下载并解压词向量（备用，本例主要使用 CodeBERT）\n",
    "# -------------------------------\n",
    "# word2vec_path = \"./autodl-fs/GoogleNews-vectors-negative300.bin\"\n",
    "# compressed_file = \"./autodl-fs/GoogleNews-vectors-negative300.bin.gz\"\n",
    "# # if not os.path.exists(word2vec_path):\n",
    "# #     logger.info(\"Downloading Word2Vec embeddings...\")\n",
    "# #     urllib.request.urlretrieve(\"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\", compressed_file)\n",
    "# #     logger.info(\"Download complete. Extracting file...\")\n",
    "# #     with gzip.open(compressed_file, 'rb') as f_in:\n",
    "# #         with open(word2vec_path, 'wb') as f_out:\n",
    "# #             shutil.copyfileobj(f_in, f_out)\n",
    "# #     logger.info(\"File extracted successfully!\")\n",
    "# #     os.remove(compressed_file)\n",
    "# # # logger.info(\"Loading Word2Vec embeddings...\")\n",
    "# word2vec = None  # 本例主要使用 CodeBERT\n",
    "\n",
    "# -------------------------------\n",
    "# 数据加载函数\n",
    "# -------------------------------\n",
    "def load_dataset(data_dir):\n",
    "    label_list, product_list, component_list, bug_list = [], [], [], []\n",
    "    label_encoder = LabelEncoder()\n",
    "    product_encoder = LabelEncoder()\n",
    "    component_encoder = LabelEncoder()\n",
    "    \n",
    "    for i in range(11):\n",
    "        file_path = os.path.join(data_dir, f\"{i}.csv\")\n",
    "        if os.path.exists(file_path):\n",
    "            try:\n",
    "                df = pd.read_csv(file_path)\n",
    "                label_list.extend(df.iloc[:, 1].astype(str).tolist())\n",
    "                product_list.extend(df.iloc[:, 2].astype(str).tolist())\n",
    "                component_list.extend(df.iloc[:, 3].astype(str).tolist())\n",
    "                bug_list.extend(df.iloc[:, 4].astype(str).tolist())\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error reading {file_path}: {e}\")\n",
    "                continue\n",
    "        else:\n",
    "            logger.warning(f\"File {file_path} does not exist.\")\n",
    "    \n",
    "    labels_encoded = label_encoder.fit_transform(label_list)\n",
    "    products_encoded = product_encoder.fit_transform(product_list)\n",
    "    components_encoded = component_encoder.fit_transform(component_list)\n",
    "    return labels_encoded, products_encoded, components_encoded, bug_list, label_encoder, product_encoder, component_encoder\n",
    "\n",
    "# -------------------------------\n",
    "# 文本转词嵌入函数\n",
    "# -------------------------------\n",
    "def text_to_embedding(text_list, max_length=BATCH_MAX_LENGTH):\n",
    "    all_word_list = []\n",
    "    # 第一步：构建词列表和文档频率统计\n",
    "    word_doc_count = {}  # 记录每个词出现在多少文档中\n",
    "    total_docs = len(text_list)\n",
    "    logger.info(f\"Computing IDF values for {total_docs} documents...\")\n",
    "    \n",
    "    # 首先遍历所有文档，统计每个词的文档频率\n",
    "    for i in range(0, len(text_list)):\n",
    "        split_text_list = [item.strip().strip(\"'\").strip(\"[\").strip(\"]\") for item in text_list[i].split(\",\")]\n",
    "        # 对文本长度进行调整\n",
    "        if (len(split_text_list) <= max_length):\n",
    "            for i in range(len(split_text_list), max_length):\n",
    "                split_text_list.append(\"pad\")\n",
    "        else:\n",
    "            split_text_list = split_text_list[:max_length]\n",
    "        \n",
    "        # 统计每个词出现的文档数（每个文档中的每个词只计算一次）\n",
    "        unique_words = set(split_text_list)\n",
    "        for word in unique_words:\n",
    "            if word in word_doc_count:\n",
    "                word_doc_count[word] += 1\n",
    "            else:\n",
    "                word_doc_count[word] = 1\n",
    "        \n",
    "        all_word_list.append(split_text_list)\n",
    "    \n",
    "    # 第二步：计算IDF值\n",
    "    word_idf = {}\n",
    "    for word, doc_count in word_doc_count.items():\n",
    "        # 使用log(N/df)计算IDF，加1平滑处理避免零除错误\n",
    "        word_idf[word] = np.log(total_docs / (doc_count + 1)) + 1.0\n",
    "    \n",
    "    # 确保\"pad\"的IDF值为0\n",
    "    word_idf[\"pad\"] = 0.0\n",
    "    \n",
    "    logger.info(f\"IDF calculation complete. Processing {len(all_word_list)} documents with Word2Vec...\")\n",
    "    print(len(all_word_list))\n",
    "    \n",
    "    # 第三步：加载或训练Word2Vec模型\n",
    "    if os.path.exists(W2VFILE):\n",
    "        w2v = Word2Vec.load(W2VFILE)\n",
    "    else:\n",
    "        w2v = Word2Vec(all_word_list,        #用于训练的语料数据\n",
    "                    vector_size=300,    #是指特征向量的维度，默认为100\n",
    "                    window=5,           #一个句子中当前单词和被预测单词的最大距离\n",
    "                    min_count=1)        #可以对字典做截断，词频少于min_count次数的单词会被丢弃掉，默认值为5\n",
    "        print(w2v.wv[\"javadoc\"])\n",
    "        w2v.wv[\"pad\"] = np.zeros(300,dtype=np.float64)\n",
    "        print(w2v.wv[\"pad\"])\n",
    "        print(len(w2v.wv[\"pad\"]))\n",
    "        w2v.save(W2VFILE)\n",
    "    \n",
    "    # 第四步：获取词嵌入并应用IDF加权\n",
    "    flatA = np.array(all_word_list).reshape(-1)\n",
    "    \n",
    "    # 创建IDF加权的词嵌入\n",
    "    idf_weighted_vectors = []\n",
    "    for word in flatA:\n",
    "        # 获取词嵌入\n",
    "        word_vector = w2v.wv[word]\n",
    "        # 获取IDF值并应用加权\n",
    "        idf_value = word_idf.get(word, 1.0)  # 如果未知词，使用默认IDF=1\n",
    "        # 应用IDF加权\n",
    "        weighted_vector = word_vector * idf_value\n",
    "        idf_weighted_vectors.append(weighted_vector)\n",
    "    \n",
    "    vectors = np.array(idf_weighted_vectors)\n",
    "    logger.info(f\"IDF-weighted word embeddings created with shape {vectors.shape}\")\n",
    "    print(vectors.shape)\n",
    "\n",
    "    result_word_tensor = torch.from_numpy(vectors).reshape(-1, max_length, 300)\n",
    "    print(result_word_tensor.shape)\n",
    "    return result_word_tensor\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# 定义增强型 Atten-CRNN 模型（包含产品和组件嵌入、残差链接与 SE 模块）\n",
    "# -------------------------------\n",
    "class AttenCRNNEnhanced(nn.Module):\n",
    "    def __init__(self, num_classes, num_products, num_components):\n",
    "        super(AttenCRNNEnhanced, self).__init__()\n",
    "        self.convs3 = nn.Conv2d(1, NUM_FILTERS, (3, EMBEDDING_DIM))\n",
    "        self.convs4 = nn.Conv2d(1, NUM_FILTERS, (4, EMBEDDING_DIM))\n",
    "        self.convs5 = nn.Conv2d(1, NUM_FILTERS, (5, EMBEDDING_DIM))\n",
    "        self.lstm = nn.LSTM(EMBEDDING_DIM, HIDDEN_DIM, batch_first=True, bidirectional=False)\n",
    "        self.se_reduction = 16\n",
    "        self.se_fc1 = nn.Linear(NUM_FILTERS * len(FILTER_SIZES), (NUM_FILTERS * len(FILTER_SIZES)) // self.se_reduction)\n",
    "        self.se_fc2 = nn.Linear((NUM_FILTERS * len(FILTER_SIZES)) // self.se_reduction, NUM_FILTERS * len(FILTER_SIZES))\n",
    "        \n",
    "        self.product_embed = nn.Embedding(num_products, 32)\n",
    "        self.component_embed = nn.Embedding(num_components, 32)\n",
    "        \n",
    "        self.total_feature_dim = NUM_FILTERS * len(FILTER_SIZES) + HIDDEN_DIM + 64\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.total_feature_dim, MATCH_COUNT)\n",
    "        self.residual = nn.Linear(self.total_feature_dim, MATCH_COUNT)\n",
    "        self.fc2 = nn.Linear(MATCH_COUNT, num_classes)\n",
    "        self.dropout = nn.Dropout(DROPOUT_RATE)\n",
    "        \n",
    "    def forward(self, text_x, prod_idx, comp_idx):\n",
    "        x = text_x.unsqueeze(1)  # (batch, 1, max_length, EMBEDDING_DIM)\n",
    "        conv3features = F.relu(self.convs3(F.pad(x,(0,0,2,0)))).squeeze(3)    # (batch, NUM_FILTERS, max_length)\n",
    "        conv4features = F.relu(self.convs4(F.pad(x,(0,0,3,0)))).squeeze(3)\n",
    "        conv5features = F.relu(self.convs5(F.pad(x,(0,0,4,0)))).squeeze(3)\n",
    "        cnn_features = torch.cat([conv3features, conv4features, conv5features], 1)  # (batch, NUM_FILTERS * len(FILTER_SIZES), max_length) batchsize 450 150\n",
    "        cnn_features_atten = [F.max_pool1d(cnn_features, cnn_features.size(2)).squeeze(2)] # (batch, NUM_FILTERS * len(FILTER_SIZES))\n",
    "        cnn_features_atten = torch.cat(cnn_features_atten, 1)\n",
    "        se = F.relu(self.se_fc1(cnn_features_atten))  \n",
    "        se = torch.sigmoid(self.se_fc2(se))\n",
    "        se = se.unsqueeze(2).expand(-1, -1, cnn_features.size(2))  # (batch, NUM_FILTERS * len(FILTER_SIZES), max_length)\n",
    "        cnn_features = cnn_features * se    # (batch, NUM_FILTERS * len(FILTER_SIZES))  batchsize 450\n",
    "        \n",
    "        lstm_out, _ = self.lstm(text_x) # (batch, max_length, HIDDEN_DIM)\n",
    "        cross_attention = torch.bmm(cnn_features,lstm_out)  # Matrix multiplication is valid\n",
    "        cross_attention = torch.softmax(cross_attention, dim=2)  # (batch, NUM_FILTERS * len(FILTER_SIZES), max_length)\n",
    "\n",
    "        cross_attention_cnn = torch.bmm(cross_attention.permute(0,2,1), cnn_features)  # (batch, HIDDEN_DIM, max_length)\n",
    "        cross_attention_lstm = torch.bmm(cross_attention, lstm_out.permute(0, 2, 1))  # (batch, NUM_FILTERS * len(FILTER_SIZES), HIDDEN_DIM)\n",
    "\n",
    "        cross_attention = torch.cat((cross_attention_cnn, cross_attention_lstm), 1)\n",
    "        cross_attention = F.max_pool1d(cross_attention, cross_attention.size(2)).squeeze(2)\n",
    "\n",
    "        cross_attention = self.dropout(cross_attention)\n",
    "        \n",
    "        prod_emb = self.product_embed(prod_idx)\n",
    "        comp_emb = self.component_embed(comp_idx)\n",
    "        \n",
    "        combined_features = torch.cat((cross_attention, prod_emb, comp_emb), 1)\n",
    "        \n",
    "        hidden = F.relu(self.fc1(combined_features) + self.residual(combined_features))\n",
    "        output = self.fc2(hidden)\n",
    "        return F.log_softmax(output, dim=1)\n",
    "\n",
    "# -------------------------------\n",
    "# 十折增量学习训练函数（引入 L2 正则化、梯度裁剪；记录当前学习率；优化评价方式与图表输出）\n",
    "# -------------------------------\n",
    "def ten_fold_incremental_learning(model, text_data, prod_data, comp_data, labels, label_encoder):\n",
    "    evaluation_accuracies = []      \n",
    "    evaluation_correct = []         \n",
    "    evaluation_total = []           \n",
    "    evaluation_true_probs = []      \n",
    "    round_final_losses = []         \n",
    "\n",
    "    loss_accuracy_fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "    \n",
    "    # 如果使用多GPU，转换为DDP模型\n",
    "    if use_multi_gpu:\n",
    "        logger.info(\"Preparing model for multi-GPU training...\")\n",
    "        # 使用DataParallel包装模型 - 简单方式\n",
    "        model = nn.DataParallel(model)\n",
    "        logger.info(f\"Model wrapped with DataParallel across {num_gpus} GPUs\")\n",
    "\n",
    "    for i in range(1, 11):\n",
    "        # if i>=5: exit()\n",
    "        try:\n",
    "            test_text = text_data[i]\n",
    "            test_labels = labels[i]\n",
    "            test_prod = prod_data[i]\n",
    "            test_comp = comp_data[i]\n",
    "        except IndexError as e:\n",
    "            logger.error(f\"Data partition index error: {e}\")\n",
    "            break\n",
    "        \n",
    "        print(\"Initializing dataloader\")\n",
    "        train_dataset = TensorDataset(torch.cat(text_data[:i]), torch.cat(prod_data[:i]), torch.cat(comp_data[:i]), torch.cat(labels[:i]))\n",
    "        test_dataset = TensorDataset(test_text, test_prod, test_comp, test_labels)\n",
    "        \n",
    "        # 调整批大小以适应多GPU训练\n",
    "        effective_batch_size = BATCH_SIZE\n",
    "        if use_multi_gpu:\n",
    "            # 确保每个GPU获得相同大小的批次\n",
    "            effective_batch_size = BATCH_SIZE * num_gpus\n",
    "            logger.info(f\"Using effective batch size: {effective_batch_size} ({BATCH_SIZE} per GPU)\")\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=effective_batch_size, shuffle=True, \n",
    "                                 pin_memory=True, num_workers=4 if use_multi_gpu else 2)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=effective_batch_size, shuffle=False, \n",
    "                                pin_memory=True, num_workers=4 if use_multi_gpu else 2)\n",
    "        print(\"Dataloader initialized\")\n",
    "        \n",
    "        optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.9)\n",
    "        \n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        batch_count = 0\n",
    "        epoch_losses = []\n",
    "        \n",
    "        for epoch in range(EPOCHS):\n",
    "            epoch_loss = 0.0\n",
    "            num_batches = 0\n",
    "            for batch in tqdm(train_loader, desc=f\"Round {i} Epoch {epoch+1}/{EPOCHS}\", leave=False):\n",
    "                num_batches += 1\n",
    "                batch_count += 1\n",
    "                batch_text, batch_prod, batch_comp, batch_Y = [b.to(device) for b in batch]\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    outputs = model(batch_text, batch_prod, batch_comp)\n",
    "                    loss = F.cross_entropy(outputs, batch_Y) / ACCUMULATION_STEPS\n",
    "                loss.backward()\n",
    "                # 梯度裁剪\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "                epoch_loss += loss.item() * ACCUMULATION_STEPS\n",
    "                if batch_count % ACCUMULATION_STEPS == 0:\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "                    batch_count = 0\n",
    "            if batch_count != 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                batch_count = 0\n",
    "            scheduler.step()\n",
    "            current_lr = scheduler.get_last_lr()[0]\n",
    "            avg_epoch_loss = epoch_loss / num_batches\n",
    "            epoch_losses.append(avg_epoch_loss)\n",
    "            logger.info(f\"Round {i}, Epoch {epoch+1}/{EPOCHS}: Avg Loss = {avg_epoch_loss:.4f}, LR = {current_lr:.6f}\")\n",
    "        \n",
    "        round_final_losses.append(epoch_losses[-1])\n",
    "        \n",
    "        ax1.cla()\n",
    "        ax1.plot(range(1, len(epoch_losses)+1), epoch_losses, marker='o', color='blue', label='Training Loss')\n",
    "        ax1.set_xlabel(\"Epoch\")\n",
    "        ax1.set_ylabel(\"Training Loss\", color='blue')\n",
    "        ax1.tick_params(axis='y', labelcolor='blue')\n",
    "        \n",
    "        model.eval()\n",
    "        correct_count = 0\n",
    "        total_count = 0\n",
    "        true_prob_sum = 0.0\n",
    "        y_pred_names = []\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                batch_text, batch_prod, batch_comp, batch_Y = [b.to(device) for b in batch]\n",
    "                outputs = model(batch_text, batch_prod, batch_comp)\n",
    "                probs = torch.exp(outputs)\n",
    "                topk_probs, topk_indices = torch.topk(probs, TOP_K, dim=1)\n",
    "                batch_Y_np = batch_Y.cpu().numpy()\n",
    "                for j in range(topk_indices.size(0)):\n",
    "                    candidates = topk_indices[j].cpu().numpy()\n",
    "                    candidate_probs = topk_probs[j].cpu().numpy()\n",
    "                    total_count += 1\n",
    "                    if batch_Y_np[j] in candidates:\n",
    "                        correct_count += 1\n",
    "                        idx = np.where(candidates == batch_Y_np[j])[0][0]\n",
    "                        true_prob_sum += candidate_probs[idx]\n",
    "                    else:\n",
    "                        true_prob_sum += 0.0\n",
    "                    y_pred_names.append(label_encoder.inverse_transform([candidates[0]])[0])\n",
    "        round_accuracy = correct_count / total_count if total_count > 0 else 0\n",
    "        avg_true_prob = true_prob_sum / total_count if total_count > 0 else 0\n",
    "        \n",
    "        evaluation_accuracies.append(round_accuracy)\n",
    "        evaluation_correct.append(correct_count)\n",
    "        evaluation_total.append(total_count)\n",
    "        evaluation_true_probs.append(avg_true_prob)\n",
    "        \n",
    "        logger.info(f\"Round {i} - TOP_K Evaluation: Correct Predictions: {correct_count}, Total Predictions: {total_count}, TOP_K Accuracy: {round_accuracy:.4f}\")\n",
    "        logger.info(f\"Round {i} - Sample predicted bug fixers (top candidate, top 10): {y_pred_names[:TOP_K]}\")\n",
    "        \n",
    "        # 保存模型时，处理多GPU模型的保存\n",
    "        if use_multi_gpu:\n",
    "            model_to_save = model.module  # 获取DataParallel中包装的原始模型\n",
    "        else:\n",
    "            model_to_save = model\n",
    "            \n",
    "        checkpoint = {\n",
    "            'epoch': EPOCHS,\n",
    "            'model_state_dict': model_to_save.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'loss': epoch_losses[-1]\n",
    "        }\n",
    "        if round_accuracy > max(evaluation_accuracies[:-1], default=0):\n",
    "            checkpoint_path = os.path.join(MODEL_SAVE_PATH, f\"model_round_{i}_best.pth\")\n",
    "            torch.save(checkpoint, checkpoint_path)\n",
    "            logger.info(f\"New best model saved at {checkpoint_path}\")\n",
    "        latest_path = os.path.join(MODEL_SAVE_PATH, f\"model_round_{i}_latest.pth\")\n",
    "        torch.save(checkpoint, latest_path)\n",
    "        logger.info(f\"Latest model for Round {i} saved at {latest_path}\")\n",
    "    \n",
    "    final_accuracy = np.mean(evaluation_accuracies) if evaluation_accuracies else 0\n",
    "    logger.info(\"Final Evaluation (Avg over 10 rounds): Accuracy: {:.4f}\".format(final_accuracy))\n",
    "    \n",
    "    rounds = range(1, len(evaluation_accuracies) + 1)\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "    color_loss = 'tab:blue'\n",
    "    ax1.set_xlabel('Round')\n",
    "    ax1.set_ylabel('Final Training Loss', color=color_loss)\n",
    "    ax1.plot(rounds, round_final_losses, marker='o', color=color_loss, label='Training Loss')\n",
    "    ax1.tick_params(axis='y', labelcolor=color_loss)\n",
    "    \n",
    "    ax2 = ax1.twinx()\n",
    "    color_acc = 'tab:red'\n",
    "    ax2.set_ylabel('TOP_K Accuracy', color=color_acc)\n",
    "    ax2.plot(rounds, evaluation_accuracies, marker='s', color=color_acc, label='TOP_K Accuracy')\n",
    "    ax2.tick_params(axis='y', labelcolor=color_acc)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.title(\"Final Training Loss and TOP_K Accuracy per Round\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    plt.ioff()\n",
    "    \n",
    "    # 清理多GPU环境\n",
    "    if use_multi_gpu:\n",
    "        cleanup_ddp()\n",
    "\n",
    "# -------------------------------\n",
    "# 主流程：加载数据、转换，并输出一次数据集详细参数信息\n",
    "# CSV 文件假设包含5列：第1列忽略，第2列为标签，第3列为产品，第4列为组件，第5列为 bug 描述\n",
    "# -------------------------------\n",
    "labels_encoded, products_encoded, components_encoded, bug_list, label_encoder, product_encoder, component_encoder = load_dataset(data_dir)\n",
    "\n",
    "# 检查本地是否存在预先保存的 bug 描述嵌入数据\n",
    "if os.path.exists(EMBEDDING_FILE):\n",
    "    logger.info(\"Loading precomputed bug embeddings from local file...\")\n",
    "    bug_tensor_full = torch.load(EMBEDDING_FILE)\n",
    "else:\n",
    "    logger.info(\"Computing bug embeddings using word2vec...\")\n",
    "    bug_tensor_full = text_to_embedding(bug_list)\n",
    "    torch.save(bug_tensor_full, EMBEDDING_FILE)\n",
    "    logger.info(\"Bug embeddings saved to local file.\") \n",
    "\n",
    "prod_tensor_full = torch.tensor(products_encoded, dtype=torch.long)\n",
    "comp_tensor_full = torch.tensor(components_encoded, dtype=torch.long)\n",
    "label_tensor_full = torch.tensor(labels_encoded, dtype=torch.long)\n",
    "\n",
    "logger.info(\"Bug Text Tensor Shape: \" + str(bug_tensor_full.shape))\n",
    "logger.info(\"Product Tensor Shape: \" + str(prod_tensor_full.shape))\n",
    "logger.info(\"Component Tensor Shape: \" + str(comp_tensor_full.shape))\n",
    "logger.info(\"Label Tensor Shape: \" + str(label_tensor_full.shape))\n",
    "\n",
    "num_parts = 11\n",
    "bug_splits = torch.chunk(bug_tensor_full, num_parts)\n",
    "prod_splits = torch.chunk(prod_tensor_full, num_parts)\n",
    "comp_splits = torch.chunk(comp_tensor_full, num_parts)\n",
    "label_splits = torch.chunk(label_tensor_full, num_parts)\n",
    "\n",
    "# 添加显存优化选项\n",
    "torch.backends.cudnn.benchmark = True  # 启用cudnn自动调优\n",
    "torch.backends.cudnn.deterministic = False  # 允许非确定性优化\n",
    "\n",
    "model = AttenCRNNEnhanced(num_classes=len(label_encoder.classes_),\n",
    "                          num_products=len(product_encoder.classes_),\n",
    "                          num_components=len(component_encoder.classes_)).to(device)\n",
    "\n",
    "# 添加多GPU分布式训练的入口点函数\n",
    "def main_worker():\n",
    "    \"\"\"主进程工作函数，用于启动分布式训练\"\"\"\n",
    "    ten_fold_incremental_learning(model, bug_splits, prod_splits, comp_splits, label_splits, label_encoder)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 单机多卡训练入口\n",
    "    if use_multi_gpu:\n",
    "        # 使用DataParallel模式直接调用\n",
    "        main_worker()\n",
    "    else:\n",
    "        # 单GPU模式\n",
    "        ten_fold_incremental_learning(model, bug_splits, prod_splits, comp_splits, label_splits, label_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f1e9c4-8099-4798-ae2d-e0f623f74bd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c220f98-69c8-4ad9-8a9b-756512bc9787",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 19:44:03,307 - INFO - Found 1 GPU. Using single GPU training.\n",
      "2025-04-17 19:44:03,307 - INFO - Found 1 GPU. Using single GPU training.\n",
      "2025-04-17 19:44:07,327 - INFO - Loading precomputed bug embeddings from local file...\n",
      "2025-04-17 19:44:07,327 - INFO - Loading precomputed bug embeddings from local file...\n",
      "2025-04-17 19:44:32,250 - INFO - Bug Text Tensor Shape: torch.Size([199947, 150, 300])\n",
      "2025-04-17 19:44:32,250 - INFO - Bug Text Tensor Shape: torch.Size([199947, 150, 300])\n",
      "2025-04-17 19:44:32,253 - INFO - Product Tensor Shape: torch.Size([199947])\n",
      "2025-04-17 19:44:32,253 - INFO - Product Tensor Shape: torch.Size([199947])\n",
      "2025-04-17 19:44:32,254 - INFO - Component Tensor Shape: torch.Size([199947])\n",
      "2025-04-17 19:44:32,254 - INFO - Component Tensor Shape: torch.Size([199947])\n",
      "2025-04-17 19:44:32,255 - INFO - Label Tensor Shape: torch.Size([199947])\n",
      "2025-04-17 19:44:32,255 - INFO - Label Tensor Shape: torch.Size([199947])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型可训练参数量: 2.30 M\n",
      "FLOPs: 0.168 G  |  参数量 (thop 计算): 2.27 M\n",
      "Initializing dataloader\n",
      "Dataloader initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _releaseLock at 0x7fe028166b00>                                                                      | 0/9 [00:00<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.10/logging/__init__.py\", line 228, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt: \n",
      "Exception in thread Thread-7 (_pin_memory_loop):                                                                                                           \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/root/miniconda3/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/root/miniconda3/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/miniconda3/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 54, in _pin_memory_loop\n",
      "    do_one_step()\n",
      "  File \"/root/miniconda3/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 31, in do_one_step\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/root/miniconda3/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/root/miniconda3/lib/python3.10/site-packages/torch/multiprocessing/reductions.py\", line 355, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/root/miniconda3/lib/python3.10/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/root/miniconda3/lib/python3.10/multiprocessing/resource_sharer.py\", line 86, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/root/miniconda3/lib/python3.10/multiprocessing/connection.py\", line 513, in Client\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 548\u001b[0m\n\u001b[1;32m    545\u001b[0m     main_worker()\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    547\u001b[0m     \u001b[38;5;66;03m# 单GPU模式\u001b[39;00m\n\u001b[0;32m--> 548\u001b[0m     \u001b[43mten_fold_incremental_learning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbug_splits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprod_splits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomp_splits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_splits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_encoder\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 360\u001b[0m, in \u001b[0;36mten_fold_incremental_learning\u001b[0;34m(model, text_data, prod_data, comp_data, labels, label_encoder)\u001b[0m\n\u001b[1;32m    358\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    359\u001b[0m num_batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 360\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRound \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    361\u001b[0m     num_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    362\u001b[0m     batch_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1327\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1328\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1331\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1284\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m   1283\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m-> 1284\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1285\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1286\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m    179\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m--> 180\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_full\u001b[38;5;241m.\u001b[39mnotify()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    answer_challenge(c, authkey)\n",
      "  File \"/root/miniconda3/lib/python3.10/multiprocessing/connection.py\", line 757, in answer_challenge\n",
      "    message = connection.recv_bytes(256)         # reject large message\n",
      "  File \"/root/miniconda3/lib/python3.10/multiprocessing/connection.py\", line 221, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/root/miniconda3/lib/python3.10/multiprocessing/connection.py\", line 419, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/root/miniconda3/lib/python3.10/multiprocessing/connection.py\", line 384, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import os\n",
    "import gzip\n",
    "import shutil\n",
    "import logging\n",
    "import random\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import RobertaTokenizer, RobertaModel, AutoTokenizer, AutoModel\n",
    "from gensim.models import Word2Vec\n",
    "from thop import profile   \n",
    "\n",
    "# 启用交互模式，便于实时更新图表\n",
    "plt.ion()\n",
    "\n",
    "# 设置日志记录，同时输出到文件\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "ch = logging.StreamHandler()\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)\n",
    "fh = logging.FileHandler(\"training.log\")\n",
    "fh.setFormatter(formatter)\n",
    "logger.addHandler(fh)\n",
    "\n",
    "# 设置随机种子\n",
    "seed = 30\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# 设置计算设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 检测可用GPU数量\n",
    "num_gpus = torch.cuda.device_count()\n",
    "if num_gpus > 1:\n",
    "    logger.info(f\"Found {num_gpus} GPUs! Using distributed training.\")\n",
    "    use_multi_gpu = True\n",
    "else:\n",
    "    logger.info(f\"Found {num_gpus} GPU. Using single GPU training.\")\n",
    "    use_multi_gpu = False\n",
    "\n",
    "# -------------------------------\n",
    "# 多GPU设置\n",
    "# -------------------------------\n",
    "def setup_ddp(rank, world_size):\n",
    "    \"\"\"\n",
    "    设置分布式数据并行训练\n",
    "    \"\"\"\n",
    "    if use_multi_gpu:\n",
    "        os.environ['MASTER_ADDR'] = 'localhost'\n",
    "        os.environ['MASTER_PORT'] = '12355'\n",
    "        torch.distributed.init_process_group(backend='nccl', init_method='env://', \n",
    "                                            world_size=world_size, rank=rank)\n",
    "        torch.cuda.set_device(rank)\n",
    "\n",
    "def cleanup_ddp():\n",
    "    \"\"\"\n",
    "    清理分布式训练环境\n",
    "    \"\"\"\n",
    "    if use_multi_gpu and torch.distributed.is_initialized():\n",
    "        torch.distributed.destroy_process_group()\n",
    "\n",
    "# -------------------------------\n",
    "# 加载 word2vec 模型和分词器（异常处理）\n",
    "# -------------------------------\n",
    "# logger.info(\"Loading CodeBERT model and tokenizer...\")\n",
    "# try:\n",
    "#     codebert_tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "#     codebert_model = AutoModel.from_pretrained(\"microsoft/codebert-base\")\n",
    "#     codebert_model.to(device)\n",
    "#     codebert_model.eval()\n",
    "#     logger.info(\"CodeBERT loaded successfully!\")\n",
    "# except Exception as e:\n",
    "#     logger.error(\"Failed to load word2vec model. Error: \" + str(e))\n",
    "#     raise e\n",
    "\n",
    "# -------------------------------\n",
    "# 超参数设置（针对 RTX 4090 优化后）\n",
    "# -------------------------------\n",
    "EMBEDDING_DIM = 300  # embedding 输出维度\n",
    "W2VFILE = \"./autodl-tmp/w2v.model\"\n",
    "W2VVECFILE = \"./autodl-tmp/vec.npy\"\n",
    "FILTER_SIZES = [3, 4, 5]\n",
    "NUM_FILTERS = 150\n",
    "HIDDEN_DIM = 256\n",
    "MATCH_COUNT = 240\n",
    "DROPOUT_RATE = 0.5\n",
    "LEARNING_RATE = 0.0005\n",
    "EPOCHS = 10\n",
    "K_FOLDS = 10\n",
    "BATCH_SIZE = 2048\n",
    "ACCUMULATION_STEPS = 1\n",
    "MODEL_SAVE_PATH = \"./models/\"\n",
    "TOP_K = 5\n",
    "BATCH_MAX_LENGTH = 150\n",
    "\n",
    "# -------------------------------\n",
    "# 数据路径设置\n",
    "# CSV 格式：第1列忽略，第2列为标签，第3列为产品，第4列为组件，第5列为 bug 描述\n",
    "# -------------------------------\n",
    "data_dir = \"./data/data_by_ocean/Eclipse_raw/Segmented_content/Complete_data\"\n",
    "os.makedirs(MODEL_SAVE_PATH, exist_ok=True)\n",
    "# 定义保存嵌入数据的文件名\n",
    "EMBEDDING_FILE = \"./autodl-tmp/bug_embeddings.pt\"\n",
    "\n",
    "# -------------------------------\n",
    "# 下载并解压词向量（备用，本例主要使用 CodeBERT）\n",
    "# -------------------------------\n",
    "# word2vec_path = \"./autodl-fs/GoogleNews-vectors-negative300.bin\"\n",
    "# compressed_file = \"./autodl-fs/GoogleNews-vectors-negative300.bin.gz\"\n",
    "# # if not os.path.exists(word2vec_path):\n",
    "# #     logger.info(\"Downloading Word2Vec embeddings...\")\n",
    "# #     urllib.request.urlretrieve(\"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\", compressed_file)\n",
    "# #     logger.info(\"Download complete. Extracting file...\")\n",
    "# #     with gzip.open(compressed_file, 'rb') as f_in:\n",
    "# #         with open(word2vec_path, 'wb') as f_out:\n",
    "# #             shutil.copyfileobj(f_in, f_out)\n",
    "# #     logger.info(\"File extracted successfully!\")\n",
    "# #     os.remove(compressed_file)\n",
    "# # # logger.info(\"Loading Word2Vec embeddings...\")\n",
    "# word2vec = None  # 本例主要使用 CodeBERT\n",
    "\n",
    "# -------------------------------\n",
    "# 数据加载函数\n",
    "# -------------------------------\n",
    "def load_dataset(data_dir):\n",
    "    label_list, product_list, component_list, bug_list = [], [], [], []\n",
    "    label_encoder = LabelEncoder()\n",
    "    product_encoder = LabelEncoder()\n",
    "    component_encoder = LabelEncoder()\n",
    "    \n",
    "    for i in range(11):\n",
    "        file_path = os.path.join(data_dir, f\"{i}.csv\")\n",
    "        if os.path.exists(file_path):\n",
    "            try:\n",
    "                df = pd.read_csv(file_path)\n",
    "                label_list.extend(df.iloc[:, 1].astype(str).tolist())\n",
    "                product_list.extend(df.iloc[:, 2].astype(str).tolist())\n",
    "                component_list.extend(df.iloc[:, 3].astype(str).tolist())\n",
    "                bug_list.extend(df.iloc[:, 4].astype(str).tolist())\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error reading {file_path}: {e}\")\n",
    "                continue\n",
    "        else:\n",
    "            logger.warning(f\"File {file_path} does not exist.\")\n",
    "    \n",
    "    labels_encoded = label_encoder.fit_transform(label_list)\n",
    "    products_encoded = product_encoder.fit_transform(product_list)\n",
    "    components_encoded = component_encoder.fit_transform(component_list)\n",
    "    return labels_encoded, products_encoded, components_encoded, bug_list, label_encoder, product_encoder, component_encoder\n",
    "\n",
    "# -------------------------------\n",
    "# 文本转词嵌入函数\n",
    "# -------------------------------\n",
    "def text_to_embedding(text_list, max_length=BATCH_MAX_LENGTH):\n",
    "    all_word_list = []\n",
    "    # 第一步：构建词列表和文档频率统计\n",
    "    word_doc_count = {}  # 记录每个词出现在多少文档中\n",
    "    total_docs = len(text_list)\n",
    "    logger.info(f\"Computing IDF values for {total_docs} documents...\")\n",
    "    \n",
    "    # 首先遍历所有文档，统计每个词的文档频率\n",
    "    for i in range(0, len(text_list)):\n",
    "        split_text_list = [item.strip().strip(\"'\").strip(\"[\").strip(\"]\") for item in text_list[i].split(\",\")]\n",
    "        # 对文本长度进行调整\n",
    "        if (len(split_text_list) <= max_length):\n",
    "            for i in range(len(split_text_list), max_length):\n",
    "                split_text_list.append(\"pad\")\n",
    "        else:\n",
    "            split_text_list = split_text_list[:max_length]\n",
    "        \n",
    "        # 统计每个词出现的文档数（每个文档中的每个词只计算一次）\n",
    "        unique_words = set(split_text_list)\n",
    "        for word in unique_words:\n",
    "            if word in word_doc_count:\n",
    "                word_doc_count[word] += 1\n",
    "            else:\n",
    "                word_doc_count[word] = 1\n",
    "        \n",
    "        all_word_list.append(split_text_list)\n",
    "    \n",
    "    # 第二步：计算IDF值\n",
    "    word_idf = {}\n",
    "    for word, doc_count in word_doc_count.items():\n",
    "        # 使用log(N/df)计算IDF，加1平滑处理避免零除错误\n",
    "        word_idf[word] = np.log(total_docs / (doc_count + 1)) + 1.0\n",
    "    \n",
    "    # 确保\"pad\"的IDF值为0\n",
    "    word_idf[\"pad\"] = 0.0\n",
    "    \n",
    "    logger.info(f\"IDF calculation complete. Processing {len(all_word_list)} documents with Word2Vec...\")\n",
    "    print(len(all_word_list))\n",
    "    \n",
    "    # 第三步：加载或训练Word2Vec模型\n",
    "    if os.path.exists(W2VFILE):\n",
    "        w2v = Word2Vec.load(W2VFILE)\n",
    "    else:\n",
    "        w2v = Word2Vec(all_word_list,        #用于训练的语料数据\n",
    "                    vector_size=300,    #是指特征向量的维度，默认为100\n",
    "                    window=5,           #一个句子中当前单词和被预测单词的最大距离\n",
    "                    min_count=1)        #可以对字典做截断，词频少于min_count次数的单词会被丢弃掉，默认值为5\n",
    "        print(w2v.wv[\"javadoc\"])\n",
    "        w2v.wv[\"pad\"] = np.zeros(300,dtype=np.float64)\n",
    "        print(w2v.wv[\"pad\"])\n",
    "        print(len(w2v.wv[\"pad\"]))\n",
    "        w2v.save(W2VFILE)\n",
    "    \n",
    "    # 第四步：获取词嵌入并应用IDF加权\n",
    "    flatA = np.array(all_word_list).reshape(-1)\n",
    "    \n",
    "    # 创建IDF加权的词嵌入\n",
    "    idf_weighted_vectors = []\n",
    "    for word in flatA:\n",
    "        # 获取词嵌入\n",
    "        word_vector = w2v.wv[word]\n",
    "        # 获取IDF值并应用加权\n",
    "        idf_value = word_idf.get(word, 1.0)  # 如果未知词，使用默认IDF=1\n",
    "        # 应用IDF加权\n",
    "        weighted_vector = word_vector * idf_value\n",
    "        idf_weighted_vectors.append(weighted_vector)\n",
    "    \n",
    "    vectors = np.array(idf_weighted_vectors)\n",
    "    logger.info(f\"IDF-weighted word embeddings created with shape {vectors.shape}\")\n",
    "    print(vectors.shape)\n",
    "\n",
    "    result_word_tensor = torch.from_numpy(vectors).reshape(-1, max_length, 300)\n",
    "    print(result_word_tensor.shape)\n",
    "    return result_word_tensor\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# 定义增强型 Atten-CRNN 模型（包含产品和组件嵌入、残差链接与 SE 模块）\n",
    "# -------------------------------\n",
    "class AttenCRNNEnhanced(nn.Module):\n",
    "    def __init__(self, num_classes, num_products, num_components):\n",
    "        super(AttenCRNNEnhanced, self).__init__()\n",
    "        self.convs3 = nn.Conv2d(1, NUM_FILTERS, (3, EMBEDDING_DIM))\n",
    "        self.convs4 = nn.Conv2d(1, NUM_FILTERS, (4, EMBEDDING_DIM))\n",
    "        self.convs5 = nn.Conv2d(1, NUM_FILTERS, (5, EMBEDDING_DIM))\n",
    "        self.lstm = nn.LSTM(EMBEDDING_DIM, HIDDEN_DIM, batch_first=True, bidirectional=False)\n",
    "        self.se_reduction = 16\n",
    "        self.se_fc1 = nn.Linear(NUM_FILTERS * len(FILTER_SIZES), (NUM_FILTERS * len(FILTER_SIZES)) // self.se_reduction)\n",
    "        self.se_fc2 = nn.Linear((NUM_FILTERS * len(FILTER_SIZES)) // self.se_reduction, NUM_FILTERS * len(FILTER_SIZES))\n",
    "        \n",
    "        self.product_embed = nn.Embedding(num_products, 32)\n",
    "        self.component_embed = nn.Embedding(num_components, 32)\n",
    "        \n",
    "        self.total_feature_dim = NUM_FILTERS * len(FILTER_SIZES) + HIDDEN_DIM + 64\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.total_feature_dim, MATCH_COUNT)\n",
    "        self.residual = nn.Linear(self.total_feature_dim, MATCH_COUNT)\n",
    "        self.fc2 = nn.Linear(MATCH_COUNT, num_classes)\n",
    "        self.dropout = nn.Dropout(DROPOUT_RATE)\n",
    "        \n",
    "    def forward(self, text_x, prod_idx, comp_idx):\n",
    "        x = text_x.unsqueeze(1)  # (batch, 1, max_length, EMBEDDING_DIM)\n",
    "        conv3features = F.relu(self.convs3(F.pad(x,(0,0,2,0)))).squeeze(3)    # (batch, NUM_FILTERS, max_length)\n",
    "        conv4features = F.relu(self.convs4(F.pad(x,(0,0,3,0)))).squeeze(3)\n",
    "        conv5features = F.relu(self.convs5(F.pad(x,(0,0,4,0)))).squeeze(3)\n",
    "        cnn_features = torch.cat([conv3features, conv4features, conv5features], 1)  # (batch, NUM_FILTERS * len(FILTER_SIZES), max_length) batchsize 450 150\n",
    "        cnn_features_atten = [F.max_pool1d(cnn_features, cnn_features.size(2)).squeeze(2)] # (batch, NUM_FILTERS * len(FILTER_SIZES))\n",
    "        cnn_features_atten = torch.cat(cnn_features_atten, 1)\n",
    "        se = F.relu(self.se_fc1(cnn_features_atten))  \n",
    "        se = torch.sigmoid(self.se_fc2(se))\n",
    "        se = se.unsqueeze(2).expand(-1, -1, cnn_features.size(2))  # (batch, NUM_FILTERS * len(FILTER_SIZES), max_length)\n",
    "        cnn_features = cnn_features * se    # (batch, NUM_FILTERS * len(FILTER_SIZES))  batchsize 450\n",
    "        \n",
    "        lstm_out, _ = self.lstm(text_x) # (batch, max_length, HIDDEN_DIM)\n",
    "        cross_attention = torch.bmm(cnn_features,lstm_out)  # Matrix multiplication is valid\n",
    "        cross_attention = torch.softmax(cross_attention, dim=2)  # (batch, NUM_FILTERS * len(FILTER_SIZES), max_length)\n",
    "\n",
    "        cross_attention_cnn = torch.bmm(cross_attention.permute(0,2,1), cnn_features)  # (batch, HIDDEN_DIM, max_length)\n",
    "        cross_attention_lstm = torch.bmm(cross_attention, lstm_out.permute(0, 2, 1))  # (batch, NUM_FILTERS * len(FILTER_SIZES), HIDDEN_DIM)\n",
    "\n",
    "        cross_attention = torch.cat((cross_attention_cnn, cross_attention_lstm), 1)\n",
    "        cross_attention = F.max_pool1d(cross_attention, cross_attention.size(2)).squeeze(2)\n",
    "\n",
    "        cross_attention = self.dropout(cross_attention)\n",
    "        \n",
    "        prod_emb = self.product_embed(prod_idx)\n",
    "        comp_emb = self.component_embed(comp_idx)\n",
    "        \n",
    "        combined_features = torch.cat((cross_attention, prod_emb, comp_emb), 1)\n",
    "        \n",
    "        hidden = F.relu(self.fc1(combined_features) + self.residual(combined_features))\n",
    "        output = self.fc2(hidden)\n",
    "        return F.log_softmax(output, dim=1)\n",
    "\n",
    "# -------------------------------\n",
    "# 十折增量学习训练函数（引入 L2 正则化、梯度裁剪；记录当前学习率；优化评价方式与图表输出）\n",
    "# -------------------------------\n",
    "def ten_fold_incremental_learning(model, text_data, prod_data, comp_data, labels, label_encoder):\n",
    "    evaluation_accuracies = []      \n",
    "    evaluation_correct = []         \n",
    "    evaluation_total = []           \n",
    "    evaluation_true_probs = []      \n",
    "    round_final_losses = []         \n",
    "\n",
    "    loss_accuracy_fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "    \n",
    "    # 如果使用多GPU，转换为DDP模型\n",
    "    if use_multi_gpu:\n",
    "        logger.info(\"Preparing model for multi-GPU training...\")\n",
    "        # 使用DataParallel包装模型 - 简单方式\n",
    "        model = nn.DataParallel(model)\n",
    "        logger.info(f\"Model wrapped with DataParallel across {num_gpus} GPUs\")\n",
    "\n",
    "    for i in range(1, 11):\n",
    "        # if i>=5: exit()\n",
    "        try:\n",
    "            test_text = text_data[i]\n",
    "            test_labels = labels[i]\n",
    "            test_prod = prod_data[i]\n",
    "            test_comp = comp_data[i]\n",
    "        except IndexError as e:\n",
    "            logger.error(f\"Data partition index error: {e}\")\n",
    "            break\n",
    "        \n",
    "        print(\"Initializing dataloader\")\n",
    "        train_dataset = TensorDataset(torch.cat(text_data[:i]), torch.cat(prod_data[:i]), torch.cat(comp_data[:i]), torch.cat(labels[:i]))\n",
    "        test_dataset = TensorDataset(test_text, test_prod, test_comp, test_labels)\n",
    "        \n",
    "        # 调整批大小以适应多GPU训练\n",
    "        effective_batch_size = BATCH_SIZE\n",
    "        if use_multi_gpu:\n",
    "            # 确保每个GPU获得相同大小的批次\n",
    "            effective_batch_size = BATCH_SIZE * num_gpus\n",
    "            logger.info(f\"Using effective batch size: {effective_batch_size} ({BATCH_SIZE} per GPU)\")\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=effective_batch_size, shuffle=True, \n",
    "                                 pin_memory=True, num_workers=4 if use_multi_gpu else 2)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=effective_batch_size, shuffle=False, \n",
    "                                pin_memory=True, num_workers=4 if use_multi_gpu else 2)\n",
    "        print(\"Dataloader initialized\")\n",
    "        \n",
    "        optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.9)\n",
    "        \n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        batch_count = 0\n",
    "        epoch_losses = []\n",
    "        \n",
    "        for epoch in range(EPOCHS):\n",
    "            epoch_loss = 0.0\n",
    "            num_batches = 0\n",
    "            for batch in tqdm(train_loader, desc=f\"Round {i} Epoch {epoch+1}/{EPOCHS}\", leave=False):\n",
    "                num_batches += 1\n",
    "                batch_count += 1\n",
    "                batch_text, batch_prod, batch_comp, batch_Y = [b.to(device) for b in batch]\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    outputs = model(batch_text, batch_prod, batch_comp)\n",
    "                    loss = F.cross_entropy(outputs, batch_Y) / ACCUMULATION_STEPS\n",
    "                loss.backward()\n",
    "                # 梯度裁剪\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "                epoch_loss += loss.item() * ACCUMULATION_STEPS\n",
    "                if batch_count % ACCUMULATION_STEPS == 0:\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "                    batch_count = 0\n",
    "            if batch_count != 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                batch_count = 0\n",
    "            scheduler.step()\n",
    "            current_lr = scheduler.get_last_lr()[0]\n",
    "            avg_epoch_loss = epoch_loss / num_batches\n",
    "            epoch_losses.append(avg_epoch_loss)\n",
    "            logger.info(f\"Round {i}, Epoch {epoch+1}/{EPOCHS}: Avg Loss = {avg_epoch_loss:.4f}, LR = {current_lr:.6f}\")\n",
    "        \n",
    "        round_final_losses.append(epoch_losses[-1])\n",
    "        \n",
    "        ax1.cla()\n",
    "        ax1.plot(range(1, len(epoch_losses)+1), epoch_losses, marker='o', color='blue', label='Training Loss')\n",
    "        ax1.set_xlabel(\"Epoch\")\n",
    "        ax1.set_ylabel(\"Training Loss\", color='blue')\n",
    "        ax1.tick_params(axis='y', labelcolor='blue')\n",
    "        \n",
    "        model.eval()\n",
    "        correct_count = 0\n",
    "        total_count = 0\n",
    "        true_prob_sum = 0.0\n",
    "        y_pred_names = []\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                batch_text, batch_prod, batch_comp, batch_Y = [b.to(device) for b in batch]\n",
    "                outputs = model(batch_text, batch_prod, batch_comp)\n",
    "                probs = torch.exp(outputs)\n",
    "                topk_probs, topk_indices = torch.topk(probs, TOP_K, dim=1)\n",
    "                batch_Y_np = batch_Y.cpu().numpy()\n",
    "                for j in range(topk_indices.size(0)):\n",
    "                    candidates = topk_indices[j].cpu().numpy()\n",
    "                    candidate_probs = topk_probs[j].cpu().numpy()\n",
    "                    total_count += 1\n",
    "                    if batch_Y_np[j] in candidates:\n",
    "                        correct_count += 1\n",
    "                        idx = np.where(candidates == batch_Y_np[j])[0][0]\n",
    "                        true_prob_sum += candidate_probs[idx]\n",
    "                    else:\n",
    "                        true_prob_sum += 0.0\n",
    "                    y_pred_names.append(label_encoder.inverse_transform([candidates[0]])[0])\n",
    "        round_accuracy = correct_count / total_count if total_count > 0 else 0\n",
    "        avg_true_prob = true_prob_sum / total_count if total_count > 0 else 0\n",
    "        \n",
    "        evaluation_accuracies.append(round_accuracy)\n",
    "        evaluation_correct.append(correct_count)\n",
    "        evaluation_total.append(total_count)\n",
    "        evaluation_true_probs.append(avg_true_prob)\n",
    "        \n",
    "        logger.info(f\"Round {i} - TOP_K Evaluation: Correct Predictions: {correct_count}, Total Predictions: {total_count}, TOP_K Accuracy: {round_accuracy:.4f}\")\n",
    "        logger.info(f\"Round {i} - Sample predicted bug fixers (top candidate, top 10): {y_pred_names[:TOP_K]}\")\n",
    "        \n",
    "        # 保存模型时，处理多GPU模型的保存\n",
    "        if use_multi_gpu:\n",
    "            model_to_save = model.module  # 获取DataParallel中包装的原始模型\n",
    "        else:\n",
    "            model_to_save = model\n",
    "            \n",
    "        checkpoint = {\n",
    "            'epoch': EPOCHS,\n",
    "            'model_state_dict': model_to_save.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'loss': epoch_losses[-1]\n",
    "        }\n",
    "        if round_accuracy > max(evaluation_accuracies[:-1], default=0):\n",
    "            checkpoint_path = os.path.join(MODEL_SAVE_PATH, f\"model_round_{i}_best.pth\")\n",
    "            torch.save(checkpoint, checkpoint_path)\n",
    "            logger.info(f\"New best model saved at {checkpoint_path}\")\n",
    "        latest_path = os.path.join(MODEL_SAVE_PATH, f\"model_round_{i}_latest.pth\")\n",
    "        torch.save(checkpoint, latest_path)\n",
    "        logger.info(f\"Latest model for Round {i} saved at {latest_path}\")\n",
    "    \n",
    "    final_accuracy = np.mean(evaluation_accuracies) if evaluation_accuracies else 0\n",
    "    logger.info(\"Final Evaluation (Avg over 10 rounds): Accuracy: {:.4f}\".format(final_accuracy))\n",
    "    \n",
    "    rounds = range(1, len(evaluation_accuracies) + 1)\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "    color_loss = 'tab:blue'\n",
    "    ax1.set_xlabel('Round')\n",
    "    ax1.set_ylabel('Final Training Loss', color=color_loss)\n",
    "    ax1.plot(rounds, round_final_losses, marker='o', color=color_loss, label='Training Loss')\n",
    "    ax1.tick_params(axis='y', labelcolor=color_loss)\n",
    "    \n",
    "    ax2 = ax1.twinx()\n",
    "    color_acc = 'tab:red'\n",
    "    ax2.set_ylabel('TOP_K Accuracy', color=color_acc)\n",
    "    ax2.plot(rounds, evaluation_accuracies, marker='s', color=color_acc, label='TOP_K Accuracy')\n",
    "    ax2.tick_params(axis='y', labelcolor=color_acc)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.title(\"Final Training Loss and TOP_K Accuracy per Round\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    plt.ioff()\n",
    "    \n",
    "    # 清理多GPU环境\n",
    "    if use_multi_gpu:\n",
    "        cleanup_ddp()\n",
    "\n",
    "# -------------------------------\n",
    "# 主流程：加载数据、转换，并输出一次数据集详细参数信息\n",
    "# CSV 文件假设包含5列：第1列忽略，第2列为标签，第3列为产品，第4列为组件，第5列为 bug 描述\n",
    "# -------------------------------\n",
    "labels_encoded, products_encoded, components_encoded, bug_list, label_encoder, product_encoder, component_encoder = load_dataset(data_dir)\n",
    "\n",
    "# 检查本地是否存在预先保存的 bug 描述嵌入数据\n",
    "if os.path.exists(EMBEDDING_FILE):\n",
    "    logger.info(\"Loading precomputed bug embeddings from local file...\")\n",
    "    bug_tensor_full = torch.load(EMBEDDING_FILE)\n",
    "else:\n",
    "    logger.info(\"Computing bug embeddings using word2vec...\")\n",
    "    bug_tensor_full = text_to_embedding(bug_list)\n",
    "    torch.save(bug_tensor_full, EMBEDDING_FILE)\n",
    "    logger.info(\"Bug embeddings saved to local file.\") \n",
    "\n",
    "prod_tensor_full = torch.tensor(products_encoded, dtype=torch.long)\n",
    "comp_tensor_full = torch.tensor(components_encoded, dtype=torch.long)\n",
    "label_tensor_full = torch.tensor(labels_encoded, dtype=torch.long)\n",
    "\n",
    "logger.info(\"Bug Text Tensor Shape: \" + str(bug_tensor_full.shape))\n",
    "logger.info(\"Product Tensor Shape: \" + str(prod_tensor_full.shape))\n",
    "logger.info(\"Component Tensor Shape: \" + str(comp_tensor_full.shape))\n",
    "logger.info(\"Label Tensor Shape: \" + str(label_tensor_full.shape))\n",
    "\n",
    "num_parts = 11\n",
    "bug_splits = torch.chunk(bug_tensor_full, num_parts)\n",
    "prod_splits = torch.chunk(prod_tensor_full, num_parts)\n",
    "comp_splits = torch.chunk(comp_tensor_full, num_parts)\n",
    "label_splits = torch.chunk(label_tensor_full, num_parts)\n",
    "\n",
    "# 添加显存优化选项\n",
    "torch.backends.cudnn.benchmark = True  # 启用cudnn自动调优\n",
    "torch.backends.cudnn.deterministic = False  # 允许非确定性优化\n",
    "\n",
    "model = AttenCRNNEnhanced(num_classes=len(label_encoder.classes_),\n",
    "                          num_products=len(product_encoder.classes_),\n",
    "                          num_components=len(component_encoder.classes_)).to(device)\n",
    "\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# 2. 统计参数量\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"模型可训练参数量: {total_params / 1e6:.2f} M\")\n",
    "\n",
    "# 3. 统计 FLOPs（以单样本输入为例）\n",
    "#    输入维度: (batch_size=1, seq_len=BATCH_MAX_LENGTH, embed_dim=EMBEDDING_DIM)\n",
    "dummy_text = torch.randn(1, BATCH_MAX_LENGTH, EMBEDDING_DIM).to(device)\n",
    "dummy_prod = torch.zeros(1, dtype=torch.long).to(device)\n",
    "dummy_comp = torch.zeros(1, dtype=torch.long).to(device)\n",
    "\n",
    "flops, params = profile(\n",
    "    model, \n",
    "    inputs=(dummy_text, dummy_prod, dummy_comp),\n",
    "    verbose=False\n",
    ")\n",
    "print(f\"FLOPs: {flops / 1e9:.3f} G  |  参数量 (thop 计算): {params / 1e6:.2f} M\")\n",
    "\n",
    "\n",
    "# 添加多GPU分布式训练的入口点函数\n",
    "def main_worker():\n",
    "    \"\"\"主进程工作函数，用于启动分布式训练\"\"\"\n",
    "    ten_fold_incremental_learning(model, bug_splits, prod_splits, comp_splits, label_splits, label_encoder)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 单机多卡训练入口\n",
    "    if use_multi_gpu:\n",
    "        # 使用DataParallel模式直接调用\n",
    "        main_worker()\n",
    "    else:\n",
    "        # 单GPU模式\n",
    "        ten_fold_incremental_learning(model, bug_splits, prod_splits, comp_splits, label_splits, label_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae0f18f-cd19-4b49-b134-d5f4ef2e0899",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8857faf1-76ab-4c96-9a21-51530f62dcfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
